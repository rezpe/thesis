@article{NAVARES2020109254,
title = {Direct assessment of health impacts on hospital admission from traffic intensity in Madrid},
journal = {Environmental Research},
volume = {184},
pages = {109254},
year = {2020},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2020.109254},
url = {https://www.sciencedirect.com/science/article/pii/S0013935120301468},
author = {Ricardo Navares and Julio Diaz and Jose L. Aznarte and Cristina Linares},
keywords = {Traffic intensity, Hospital admissions, Attributable risk, ARIMA, Poisson regression},
abstract = {In this paper we establish the attributable risk on respiratory and cardiovascular disorders related to traffic intensity in Madrid. In contrast to previous related studies, the proposed approach directly associates road traffic counts to patient emergency admission rates instead of using primary air pollutants. By applying Shapley values over gradient boosting machines, a first selection step is performed among all traffic observation points based on their influence on patient emergency admissions at Gregorio Marañon hospital. A subsequent quantification of the relative risk associated to traffic intensity of the selected point is calculated via ARIMA and log-linear Poisson regression models. The results obtained show that 13\% of respiratory cases are related to traffic intensity while, in the case of cardiovascular disorders, the percentage increases to 39\%.}
}

@article{lee_air_2014,
	title = {Air {Pollution} {Exposure} and {Cardiovascular} {Disease}},
	volume = {30},
	issn = {1976-8257},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4112067/},
	doi = {10.5487/TR.2014.30.2.071},
	abstract = {Ambient air pollution (AAP) and particulate matters (PM) have been closely associated with adverse health effects such as respiratory disease and cardiovascular diseases. Previous studies have examined the adverse health effects associated with short- and long-term exposure to AAP and outdoor PM on respiratory disease. However, the effect of PM size (PM2.5 and PM10) on cardiovascular disease has not been well studied. Thus, it remains unclear how the size of the inhalable particles (coarse, fine, or ultrafine) affects mortality and morbidity. Airborne PM concentrations are commonly used for ambient air quality management worldwide, owing to the known effects on cardiorespiratory health. In this article, we assess the relationship between cardiovascular diseases and PM, with a particular focus on PM size. We discuss the association of PM2.5 and PM10, nitrogen dioxide (NO2), and elemental carbon with mortality and morbidity due to cardiovascular diseases, stroke, and altered blood pressure, based on epidemiological studies. In addition, we provide evidence that the adverse health effects of AAP and PM are more pronounced among the elderly, children, and people with preexisting cardiovascular and respiratory conditions. Finally, we critically summarize the literature pertaining to cardiovascular diseases, including atherosclerosis and stroke, and introduce potential studies to better understand the health significance of AAP and PM on cardiovascular
disease.},
	number = {2},
	urldate = {2024-01-14},
	journal = {Toxicological Research},
	author = {Lee, Byeong-Jae and Kim, Bumseok and Lee, Kyuhong},
	month = {jun},
	year = {2014},
	pmid = {25071915},
	pmcid = {PMC4112067},
	pages = {71--75},
}

@article{kurt_pulmonary_2016,
	title = {Pulmonary {Health} {Effects} of {Air} {Pollution}},
	volume = {22},
	issn = {1070-5287},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4776742/},
	doi = {10.1097/MCP.0000000000000248},
	abstract = {Purpose of the review
Air pollution continues to be a major public health concern affecting nine out of ten individuals living in urban areas worldwide. Exposure to air pollution is the ninth leading risk factor for cardiopulmonary mortality. The aim of this review is to examine the current literature for the most recent updates on health effects of specific air pollutants and their impact on asthma, chronic obstructive pulmonary disease (COPD), lung cancer and respiratory infection.

Recent findings
A total of 53 publications were reviewed to establish new insights as to how air pollution is associated with pulmonary morbidity and mortality. Considerable past evidence suggests that air pollution is an important factor that enhances pulmonary disease, while also causing greater harm in susceptible populations, such as children, the elderly and those of low socio-economic status worldwide. Asthma, COPD, lung cancer and respiratory infections all seem to be exacerbated due to exposure to a variety of environmental air pollutants with the greatest effects due to particulate matter (PM), ozone and nitrogen oxides. New publications reviewed reaffirm these findings.

Summary
Continued vigilence will be essential to lessen the effects of air pollution on human health and pulmonary disease. Cooperation at a multi-national level will be required on the part of governments, industry, energy-based enterprises and the public working together to solve our air quality issues at the local, national and global level.},
	number = {2},
	urldate = {2024-01-14},
	journal = {Current opinion in pulmonary medicine},
	author = {Kurt, Ozlem Kar and Zhang, Jingjing and Pinkerton, Kent E.},
	month = {mar},
	year = {2016},
	pmid = {26761628},
	pmcid = {PMC4776742},
	pages = {138--143},
}

@article{eze_long-term_2014,
	title = {Long-term air pollution exposure and diabetes in a population-based {Swiss} cohort},
	volume = {70},
	issn = {0160-4120},
	url = {https://www.sciencedirect.com/science/article/pii/S0160412014001573},
	doi = {10.1016/j.envint.2014.05.014},
	abstract = {Air pollution is an important risk factor for global burden of disease. There has been recent interest in its possible role in the etiology of diabetes mellitus. Experimental evidence is suggestive, but epidemiological evidence is limited and mixed. We therefore explored the association between air pollution and prevalent diabetes, in a population-based Swiss cohort. We did cross-sectional analyses of 6392 participants of the Swiss Cohort Study on Air Pollution and Lung and Heart Diseases in Adults [SAPALDIA], aged between 29 and 73years. We used estimates of average individual home outdoor PM10 [particulate matter {\textless}10μm in diameter] and NO2 [nitrogen dioxide] exposure over the 10years preceding the survey. Their association with diabetes was modeled using mixed logistic regression models, including participants' study area as random effect, with incremental adjustment for confounders. There were 315 cases of diabetes (prevalence: 5.5\% [95\% confidence interval (CI): 2.8, 7.2\%]). Both PM10 and NO2 were associated with prevalent diabetes with respective odds ratios of 1.40 [95\% CI: 1.17, 1.67] and 1.19 [95\% CI: 1.03, 1.38] per 10μg/m3 increase in the average home outdoor level. Associations with PM10 were generally stronger than with NO2, even in the two-pollutant model. There was some indication that beta blockers mitigated the effect of PM10. The associations remained stable across different sensitivity analyses. Our study adds to the evidence that long term air pollution exposure is associated with diabetes mellitus. PM10 appears to be a useful marker of aspects of air pollution relevant for diabetes. This association can be observed at concentrations below air quality guidelines.},
	urldate = {2024-01-14},
	journal = {Environment International},
	author = {Eze, Ikenna C. and Schaffner, Emmanuel and Fischer, Evelyn and Schikowski, Tamara and Adam, Martin and Imboden, Medea and Tsai, Ming and Carballo, David and von Eckardstein, Arnold and Künzli, Nino and Schindler, Christian and Probst-Hensch, Nicole},
	month = {sep},
	year = {2014},
	keywords = {Air pollution, Type 2 diabetes, PM, NO, Epidemiology, Association analysis},
	pages = {95--105},
}

@article{bowe_particulate_2018,
	title = {Particulate {Matter} {Air} {Pollution} and the {Risk} of {Incident} {CKD} and {Progression} to {ESRD}},
	volume = {29},
	issn = {1046-6673},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5748906/},
	doi = {10.1681/ASN.2017030253},
	abstract = {Elevated levels of fine particulate matter {\textless}2.5 µm in aerodynamic diameter (PM2.5) are associated with increased risk of cardiovascular outcomes and death, but their association with risk of CKD and ESRD is unknown. We linked the Environmental Protection Agency and the Department of Veterans Affairs databases to build an observational cohort of 2,482,737 United States veterans, and used survival models to evaluate the association of PM2.5 concentrations and risk of incident eGFR {\textless}60 ml/min per 1.73 m2, incident CKD, eGFR decline ≥30\%, and ESRD over a median follow-up of 8.52 years. County-level exposure was defined at baseline as the annual average PM2.5 concentrations in 2004, and separately as time-varying where it was updated annually and as cohort participants moved. In analyses of baseline exposure (median, 11.8 [interquartile range, 10.1–13.7] µg/m3), a 10-µg/m3 increase in PM2.5 concentration was associated with increased risk of eGFR{\textless}60 ml/min per 1.73 m2 (hazard ratio [HR], 1.21; 95\% confidence interval [95\% CI], 1.14 to 1.29), CKD (HR, 1.27; 95\% CI, 1.17 to 1.38), eGFR decline ≥30\% (HR, 1.28; 95\% CI, 1.18 to 1.39), and ESRD (HR, 1.26; 95\% CI, 1.17 to 1.35). In time-varying analyses, a 10-µg/m3 increase in PM2.5 concentration was associated with similarly increased risk of eGFR{\textless}60 ml/min per 1.73 m2, CKD, eGFR decline ≥30\%, and ESRD. Spline analyses showed a linear relationship between PM2.5 concentrations and risk of kidney outcomes. Exposure estimates derived from National Aeronautics and Space Administration satellite data yielded consistent results. Our findings demonstrate a significant association between exposure to PM2.5 and risk of incident CKD, eGFR decline, and ESRD.,},
	number = {1},
	urldate = {2024-01-14},
	journal = {Journal of the American Society of Nephrology : JASN},
	author = {Bowe, Benjamin and Xie, Yan and Li, Tingting and Yan, Yan and Xian, Hong and Al-Aly, Ziyad},
	month = {jan},
	year = {2018},
	pmid = {28935655},
	pmcid = {PMC5748906},
	pages = {218--230},
}

@article{tang_mortality_2017,
	title = {Mortality and air pollution in {Beijing}: {The} long-term relationship},
	volume = {150},
	issn = {1352-2310},
	shorttitle = {Mortality and air pollution in {Beijing}},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231016309293},
	doi = {10.1016/j.atmosenv.2016.11.045},
	abstract = {Since the 1980s, air pollution has become a major problem in northern China. Exposure to the extremely high concentrations of aerosols and trace gases might lead to important human health outcomes, including respiratory, cardiovascular and cerebrovascular diseases and malignant tumours. In this study, we collected data on mortality, visibility and the concentrations of certain air pollutants in Beijing from 1949 to 2011. Our goal was to investigate the mortality trends of different types of diseases and the relationship between mortality and air pollution. Based on the chemical compositions in particles and satellite formaldehyde, we found that mortality due to circulatory diseases was correlated with sulphate, nitrate and formaldehyde, whereas respiratory diseases were correlated with calcium, sulphate and nitrate, and malignant tumours was correlated with ammonium, nitrate and formaldehyde with an 11-year lag. The different responses to different air pollutants for different diseases are primarily a result of energy usage.},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Tang, Guiqian and Zhao, Pusheng and Wang, Yinghong and Gao, Wenkang and Cheng, Mengtian and Xin, Jinyuan and Li, Xin and Wang, Yuesi},
	month = {feb},
	year = {2017},
	keywords = {Mortality, Air pollution, Beijing, Disease},
	pages = {238--243},
}

@article{lee_traffic-related_2016,
	title = {Traffic-related air pollution increased the risk of {Parkinson}'s disease in {Taiwan}: {A} nationwide study},
	volume = {96},
	issn = {0160-4120},
	shorttitle = {Traffic-related air pollution increased the risk of {Parkinson}'s disease in {Taiwan}},
	url = {https://www.sciencedirect.com/science/article/pii/S0160412016303075},
	doi = {10.1016/j.envint.2016.08.017},
	abstract = {Background
Ambient air pollution has been associated with many health conditions, but little is known about its effects on neurodegenerative diseases, such as Parkinson's disease (PD). In this study, we investigated the influence of ambient air pollution on PD in a nationwide population-based case–control study in Taiwan.
Methods
We identified 11,117 incident PD patients between 2007 and 2009 from the Taiwanese National Health Insurance Research Database and selected 44,468 age- and gender-matched population controls from the longitudinal health insurance database. The average ambient pollutant exposure concentrations from 1998 through the onset of PD were estimated using quantile-based Bayesian Maximum Entropy models. Basing from logistic regression models, we estimated the odds ratios (ORs) and 95\% confidence intervals (CIs) of ambient pollutant exposures and PD risk.
Results
We observed positive associations between NOx, CO exposures, and PD. In multi-pollutant models, for NOx and CO above the 75th percentile exposure compared with the lowest percentile, the ORs of PD were 1.37 (95\% CI=1.23–1.52) and 1.17 (95\% CI=1.07–1.27), respectively.
Conclusions
This study suggests that ambient air pollution exposure, especially from traffic-related pollutants such as NOx and CO, increases PD risk in the Taiwanese population.},
	urldate = {2024-01-14},
	journal = {Environment International},
	author = {Lee, Pei-Chen and Liu, Li-Ling and Sun, Yu and Chen, Yu-An and Liu, Chih-Ching and Li, Chung-Yi and Yu, Hwa-Lung and Ritz, Beate},
	month = {nov},
	year = {2016},
	keywords = {Ambient air pollution, Parkinson's disease},
	pages = {75--81},
}

@article{landrigan_pollution_2018,
	title = {Pollution and {Global} {Health} – {An} {Agenda} for {Prevention}},
	volume = {126},
	issn = {0091-6765},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6108842/},
	doi = {10.1289/EHP3141},
	abstract = {Pollution is a major, overlooked, global health threat that was responsible in 2015 for an estimated 9 million deaths and great economic losses. To end neglect of pollution and advance prevention of pollution-related disease, we formed the Lancet Commission on Pollution and Health. Despite recent gains in understanding of pollution and its health effects, this Commission noted that large gaps in knowledge remain. To close these gaps and guide prevention, the Commission made research recommendations and proposed creation of a Global Observatory on Pollution and Health. We posit that successful pollution research will be translational and based on transdisciplinary collaborations among exposure science, epidemiology, data science, engineering, health policy, and economics. We envision that the Global Observatory on Pollution and Health will be a multinational consortium based at Boston College and the Harvard T.H. Chan School of Public Health that will aggregate, geocode, and archive data on pollution and pollution-related disease; analyze these data to discern trends, geographic patterns, and opportunities for intervention; and make its findings available to policymakers, the media, and the global public to catalyze research, inform policy, and assist cities and countries to target pollution, track progress, and save lives. https://doi.org/10.1289/EHP3141},
	number = {8},
	urldate = {2024-01-14},
	journal = {Environmental Health Perspectives},
	author = {Landrigan, Philip J. and Fuller, Richard and Hu, Howard and Caravanos, Jack and Cropper, Maureen L. and Hanrahan, David and Sandilya, Karti and Chiles, Thomas C. and Kumar, Pushpam and Suk, William A.},
	month = {aug},
	year = {2018},
	pmid = {30118434},
	pmcid = {PMC6108842},
	pages = {084501},
}

@article{gonzalez-garcia_environmental_2021,
	title = {Environmental profile of the municipality of {Madrid} through the methodologies of {Urban} {Metabolism} and {Life} {Cycle} {Analysis}},
	volume = {64},
	issn = {2210-6707},
	url = {https://www.sciencedirect.com/science/article/pii/S2210670720307629},
	doi = {10.1016/j.scs.2020.102546},
	abstract = {Cities are important consumers of resources and producers of waste derived from the lifestyle and daily needs of their citizens, which is why they are considered the main actors responsible for the environmental impacts related to anthropogenic activities. The quantification of these impacts is fundamental for the definition of sustainable cities. In this work, a material flow accounting study combined with the Life Cycle Assessment approach is conducted for the municipality of Madrid, the most populated city of Spain. The findings of this study allow performing a sustainability diagnosis of a large city such as Madrid, identifying energy needs, food consumption and manufactures as environmental hotspots. In addressing the comprehensive analysis of available data, important constraints arise, such as access to data. To this end, not only the development of precise estimation tools to quantify these flows, but also greater transparency of data sources, are fundamental elements in the study of the sustainability indicators proposed in this paper. Therefore, the success of any proposed sustainability strategy depends on the involvement of policy-makers and citizens in the objectives and measures set, as well as on the access to information and training on sustainability as fundamental action line driven by local government.},
	urldate = {2024-01-14},
	journal = {Sustainable Cities and Society},
	author = {González-García, Sara and Caamaño, Manuel Rama and Moreira, María Teresa and Feijoo, Gumersindo},
	month = {jan},
	year = {2021},
	keywords = {Environmental impacts, Industrial ecology, Material flow analysis, Sustainable city},
	pages = {102546},
}

@article{aguilar_relationship_2021,
	title = {Relationship between air pollution levels in {Madrid} and the natural history of idiopathic pulmonary fibrosis: severity and mortality},
	volume = {49},
	issn = {0300-0605, 1473-2300},
	shorttitle = {Relationship between air pollution levels in {Madrid} and the natural history of idiopathic pulmonary fibrosis},
	url = {http://journals.sagepub.com/doi/10.1177/03000605211029058},
	doi = {10.1177/03000605211029058},
	abstract = {Objective
              },
	language = {en},
	number = {7},
	urldate = {2024-01-14},
	journal = {Journal of International Medical Research},
	author = {Aguilar, Pablo Mariscal and Carrera, Luis Gómez and Segura, Carlos Carpio and Sánchez, María Isabel Torres and Peña, María Fernández-Velilla and Hernán, Gema Bonilla and Rodríguez, Isabel Esteban and Zapata, Rita María Regojo and Lucas, Ester Zamarrón De and Álvarez, Prudencio Díaz-Agero and Bueno, Elena Villamañán and Sánchez, Concepción Prados and Walther, Rodolfo Álvarez-Sala},
	month = {jul},
	year = {2021},
	pages = {030006052110290},
}

@article{wong_wrf-cmaq_2012,
	title = {{WRF}-{CMAQ} two-way coupled system with aerosol feedback: software development and preliminary results},
	volume = {5},
	issn = {1991-959X},
	shorttitle = {{WRF}-{CMAQ} two-way coupled system with aerosol feedback},
	url = {https://gmd.copernicus.org/articles/5/299/2012/},
	doi = {10.5194/gmd-5-299-2012},
	abstract = {Air quality models such as the EPA Community Multiscale Air Quality (CMAQ) require meteorological data as part of the input to drive the chemistry and transport simulation. The Meteorology-Chemistry Interface Processor (MCIP) is used to convert meteorological data into CMAQ-ready input. Key shortcoming of such one-way coupling include: excessive temporal interpolation of coarsely saved meteorological input and lack of feedback of atmospheric pollutant loading on simulated dynamics. We have developed a two-way coupled system to address these issues. A single source code principle was used to construct this two-way coupling system so that CMAQ can be consistently executed as a stand-alone model or part of the coupled system without any code changes; this approach eliminates maintenance of separate code versions for the coupled and uncoupled systems. The design also provides the flexibility to permit users: (1) to adjust the call frequency of WRF and CMAQ to balance the accuracy of the simulation versus computational intensity of the system, and (2) to execute the two-way coupling system with feedbacks to study the effect of gases and aerosols on short wave radiation and subsequent simulated dynamics. Details on the development and implementation of this two-way coupled system are provided. When the coupled system is executed without radiative feedback, computational time is virtually identical when using the Community Atmospheric Model (CAM) radiation option and a slightly increased ({\textasciitilde}8.5\%) when using the Rapid Radiative Transfer Model for GCMs (RRTMG) radiation option in the coupled system compared to the offline WRF-CMAQ system. Once the feedback mechanism is turned on, the execution time increases only slightly with CAM but increases about 60\% with RRTMG due to the use of a more detailed Mie calculation in this implementation of feedback mechanism. This two-way model with radiative feedback shows noticeably reduced bias in simulated surface shortwave radiation and 2-m temperatures as well improved correlation of simulated ambient ozone and PM2.5 relative to observed values for a test case with significant tropospheric aerosol loading from California wildfires.},
	language = {English},
	number = {2},
	urldate = {2024-01-14},
	journal = {Geoscientific Model Development},
	author = {Wong, D. C. and Pleim, J. and Mathur, R. and Binkowski, F. and Otte, T. and Gilliam, R. and Pouliot, G. and Xiu, A. and Young, J. O. and Kang, D.},
	month = {mar},
	year = {2012},
	pages = {299--312},
}

@incollection{eliassen_aspects_1984,
	address = {Boston, MA},
	series = {Nato  Challenges of Modern Society},
	title = {Aspects of Lagrangian Air Pollution Modelling},
	isbn = {9781461326915},
	url = {https://doi.org/10.1007/978-1-4613-2691-5\_1},
	abstract = {Lagrangian models are models in which parcels of air are followed as they blow with the wind. The models keep track of the pollutant content of the parcels. This is in contrast to Eulerian models, where the integration of the mass-balance equation is performed in a geographically fixed grid. Lagrangian models are popular, because their basic principle is easy to grasp also for nonprofessionals. In addition some numerical problems associated with the advection terms in the Eulerian mass-balance equation are avoided by Lagrangian models.},
	language = {en},
	urldate = {2024-01-14},
	booktitle = {Air {Pollution} {Modeling} and {Its} {Application} {III}},
	publisher = {Springer US},
	author = {Eliassen, Anton},
	editor = {De Wispelaere, C.},
	year = {1984},
	doi = {10.1007/978-1-4613-2691-5\_1},
	keywords = {Wind Shear, Deposition Velocity, Geostrophic Wind, Angular Spread, Lagrangian Model},
	pages = {3--21},
}

@article{romanov_graz_2020,
	title = {Graz {Lagrangian} {Model} ({GRAL}) for {Pollutants} {Tracking} and {Estimating} {Sources} {Partial} {Contributions} to {Atmospheric} {Pollution} in {Highly} {Urbanized} {Areas}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4433},
	url = {https://www.mdpi.com/2073-4433/11/12/1375},
	doi = {10.3390/atmos11121375},
	abstract = {Computational modeling allows studying the air quality problems in depth and provides the best solution reducing the population risks. This research demonstrates the Graz Lagrangian model effectiveness for assessing emission sources contributions to the air pollution: particles tracking and accumulation estimate. The article describes model setting up parameters and datasets preparation for the analysis. The experiment simulated the dispersion from the main groups of emission sources for real weather conditions during 96 h of December 2018, when significant excess of NO2, CO, SO2, PM10, and benzo(a)pyrene concentrations were observed in the Krasnoyarsk surface atmospheric layer. The computational domain was a parallelepiped of 40 × 30 × 2.5 km, which was located deep inside the Eurasian continent on a heterogeneous landscape exaggerated by high-rise buildings, with various pollutions sources and the ice-free Yenisei River. The results demonstrated an excellent applicability of the Lagrange model for hourly tracking of particle trajectories, taking into account the urban landscape. For values {\textless}1 MPC (maximum permissible concentration) of peak pollutants concentrations, the coincidences were 93 cases, and for values {\textless} 0.1 shares of MPC, there were 36 cases out of the total number of 97. The same was found for the average daily concentration for values {\textless}1 MPC—31, and for values {\textless}0.1 MPC—5 matches out of 44. Wind speeds COR—65.3\%, wind directions COR—68.6\%. The Graz Lagrangian model showed the ability to simulate air quality problems in the Krasnoyarsk greater area conditions.},
	language = {en},
	number = {12},
	urldate = {2024-01-14},
	journal = {Atmosphere},
	author = {Romanov, Aleksey A. and Gusev, Boris A. and Leonenko, Egor V. and Tamarovskaya, Anastasia N. and Vasiliev, Alexander S. and Zaytcev, Nikolai E. and Philippov, Ilia K.},
	month = {dec},
	year = {2020},
	keywords = {air quality, air dispersion modeling, GRAL, Lagrangian model, air pollutants tracking, computational fluid dynamics, model performance evaluation},
	pages = {1375},
}

@article{georgiou_evaluation_2022,
	title = {Evaluation of {WRF}-{Chem} model (v3.9.1.1) real-time air quality forecasts over the {Eastern} {Mediterranean}},
	volume = {15},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/15/4129/2022/},
	doi = {10.5194/gmd-15-4129-2022},
	abstract = {We describe and evaluate a high-resolution real-time air quality forecast system over the Eastern Mediterranean, based on a regional, online coupled atmospheric chemistry and aerosol model. The Weather Research and Forecasting model coupled with Chemistry (WRF-Chem) is used to perform daily, 3 d forecasts of regulated pollutants (NO2, O3, PM2.5) over the Eastern Mediterranean, applying three nested domains with horizontal resolutions of 50, 10 and 2 km, the latter focusing on Cyprus. Natural (dust, sea-salt, biogenic) emissions are calculated online, while anthropogenic emissions are based on the Emissions Database for Global Atmospheric Research – Hemispheric Transport of Air Pollution (EDGAR-HTAP) global emission inventory. A high spatial (1 km) and temporal (hourly) anthropogenic emission inventory is used for the island of Cyprus in the innermost domain. The model skill in forecasting the concentrations of atmospheric pollutants is evaluated using measurements from a network of nine ground stations in Cyprus and compared with the forecasting skill of the EU Copernicus Atmosphere Monitoring Service (CAMS). The forecast of surface temperature, pressure, and wind speed is found to be accurate, with minor discrepancies between the modelled and observed 10 m wind speed at mountainous and coastal sites attributed to the limited representation of the complex topography of Cyprus. Compared to CAMS, the WRF-Chem model predicts with higher accuracy the NO2 mixing ratios at the residential site with a normalized mean bias (NMB) of 7 \% during winter and −44 \% during summer, whereas the corresponding biases for CAMS are −81 \% and −84 \%. Due to the high temporal resolution of the anthropogenic emission inventory, the WRF-Chem model captures more accurately the diurnal profiles of NO2 and O3 mixing ratios at the residential site. Background PM2.5 concentrations influenced by long-range transport are overestimated by the WRF-Chem model during winter (NMB = 54 \%), whereas the corresponding NMB for CAMS is 11 \%. Our results support the adoption of regional, online coupled air quality models over chemical transport models for real-time air quality forecasts.},
	language = {English},
	number = {10},
	urldate = {2024-01-14},
	journal = {Geoscientific Model Development},
	author = {Georgiou, George K. and Christoudias, Theodoros and Proestos, Yiannis and Kushta, Jonilda and Pikridas, Michael and Sciare, Jean and Savvides, Chrysanthos and Lelieveld, Jos},
	month = {may},
	year = {2022},
	pages = {4129--4146},
}

@article{smyth_comparative_2009,
	series = {Air {Pollution} {Related} to {Transport}},
	title = {A comparative performance evaluation of the {AURAMS} and {CMAQ} air-quality modelling systems},
	volume = {43},
	issn = {1352-2310},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231008010777},
	doi = {10.1016/j.atmosenv.2008.11.027},
	abstract = {A harmonized comparative performance evaluation of A Unified Regional Air-quality Modelling System (AURAMS) v1.3.1b and Community Multiscale Air Quality (CMAQ) v4.6 air-quality modelling systems was conducted on the same North American grid for July 2002 using the same emission inventories, emissions processor, and input meteorology. Comparison of AURAMS- and CMAQ-predicted O3 concentrations against hourly surface measurement data showed a lower normalized mean bias (NMB) of 20.7\% for AURAMS versus 46.4\% for CMAQ. However, AURAMS and CMAQ had more similar normalized mean errors (NMEs) of 46.9\% and 54.2\%, respectively. Both models did similarly well in predicting daily 1-h O3 maximums; however, AURAMS performed better in calculating daily minimums. CMAQ's poorer performance for O3 is partly due to its inability to correctly predict nighttime lows. Total PM2.5 hourly surface concentration was under-predicted by both AURAMS and CMAQ with NMBs of −10.4\% and −65.2\%, respectively. However, as with O3, both models had similar NMEs of 68.0\% and 70.6\%, respectively. In general, AURAMS performance was better than CMAQ for all major PM2.5 species except nitrate and elemental carbon. Both models significantly under-predicted total organic aerosols (TOAs), although the mean AURAMS concentration was over four times larger than CMAQ's. The under-prediction of TOA was partly due to the exclusion of forest-fire emissions. Sea-salt aerosol made up approximately 50.2\% of the AURAMS total PM2.5 surface concentration versus only 6.2\% in CMAQ when averaged over all grid cells. When averaged over land cells only, sea-salt still contributed 13.9\% to the total PM2.5 mass in AURAMS versus 2.0\% in CMAQ.},
	number = {5},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Smyth, Steven C. and Jiang, Weimin and Roth, Helmut and Moran, Michael D. and Makar, Paul A. and Yang, Fuquan and Bouchet, Véronique S. and Landry, Hugo},
	month = {feb},
	year = {2009},
	keywords = {Air quality, Particulate matter, Ozone, AURAMS, CMAQ},
	pages = {1059--1070},
}

@article{menut_chimere_2021,
	title = {The {CHIMERE} v2020r1 online chemistry-transport model},
	volume = {14},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/14/6781/2021/},
	doi = {10.5194/gmd-14-6781-2021},
	abstract = {The CHIMERE chemistry-transport model v2020r1 replaces the v2017r5 version and provides numerous novelties. The most important of these is the online coupling with the Weather Research and Forecasting (WRF) meteorological model via the OASIS3 – Model Coupling Toolkit (MCT) external coupler. The model can still be used in offline mode; the online mode enables us to take into account the direct and indirect effects of aerosols on meteorology. This coupling also enables using the meteorological parameters with sub-hourly time steps. Some new parameterizations are implemented to increase the model performance and the user's choices: dimethyl sulfide (DMS) emissions, additional schemes for secondary organic aerosol (SOA) formation with volatility basis set (VBS) and H2O, improved schemes for mineral dust, biomass burning, and sea-salt emissions. The NOx emissions from lightning are added. The model also includes the possibility to use the operator-splitting integration technique. The subgrid-scale variability calculation of concentrations due to emission activity sectors is now possible. Finally, a new vertical advection scheme has been implemented, which is able to simulate more correctly long-range transport of thin pollutant plumes.},
	language = {English},
	number = {11},
	urldate = {2024-01-14},
	journal = {Geoscientific Model Development},
	author = {Menut, Laurent and Bessagnet, Bertrand and Briant, Régis and Cholakian, Arineh and Couvidat, Florian and Mailler, Sylvain and Pennel, Romain and Siour, Guillaume and Tuccella, Paolo and Turquety, Solène and Valari, Myrto},
	month = {nov},
	year = {2021},
	pages = {6781--6811},
}

@article{ponomarev_application_2020,
	title = {Application of {Atmospheric} {Chemical} {Transport} {Models} to {Validation} of {Pollutant} {Emissions} in {Moscow}},
	volume = {33},
	issn = {2070-0393},
	url = {https://doi.org/10.1134/S1024856020040090},
	doi = {10.1134/S1024856020040090},
	abstract = {Data of multiyear observations from Mosecomonitoring network stations were used to calculate the CO, NO, NO2, SO2, and PM10 emissions from urban sources, their spatial distribution, and time variations. The emission matrix thus obtained was used in the SILAM chemical transport model to estimate the air quality in the Moscow megacity. The comparisons of the calculations with the observations, performed by applying correlation relations and Student’s test, were used to correct the emission matrix. To optimize the spatial distribution of sources and the magnitude of emissions in the Moscow megacity, air pollutant fields for the summer and winter months were calculated applying chemical transport models SILAM and COSMO-ART using emissions both calculated and available from the TNO emission inventory database. Comparison of these calculations made it possible to reduce the uncertainties of estimating the air quality in the Moscow region.},
	language = {en},
	number = {4},
	urldate = {2024-01-14},
	journal = {Atmospheric and Oceanic Optics},
	author = {Ponomarev, N. A. and Elansky, N. F. and Kirsanov, A. A. and Postylyakov, O. V. and Borovski, A. N. and Verevkin, Y. M.},
	month = {jul},
	year = {2020},
	keywords = {megacity, atmospheric composition, trace gases, emissions, numerical modeling, air quality},
	pages = {362--371},
}

@article{liu_air_2022,
	title = {Air quality prediction models based on meteorological factors and real-time data of industrial waste gas},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-13579-2},
	doi = {10.1038/s41598-022-13579-2},
	abstract = {With the rapid economic growth, air quality continues to decline. High-intensity pollution emissions and unfavorable weather conditions are the key factors for the formation and development of air heavy pollution processes. Given that research into air quality prediction generally ignore pollutant emission information, in this paper, the random forest supervised learning algorithm is used to construct an air quality prediction model for Zhangdian District with industrial waste gas daily emissions and meteorological factors as variables. The training data include the air quality index (AQI) values, meteorological factors and industrial waste gas daily emission of Zhangdian District from 1st January 2017 to 30th November 2019. The data from 1st to 31th December 2019 is used as the test set to assess the model. The performance of the model is analysed and compared with the backpropagation (BP) neural network, decision tree, and least squares support vector machine (LSSVM) function, which has better overall prediction performance with an RMSE of 22.91 and an MAE of 15.80. Based on meteorological forecasts and expected air quality, a daily emission limit for industrial waste gas can be obtained using model inversion. From 1st to 31th December 2019, if the industrial waste gas daily emission in this area were decreased from 6048.5 million cubic meters of waste gas to 5687.5 million cubic meters, and the daily air quality would be maintained at a good level. This paper deeply explores the dynamic relationship between waste gas daily emissions of industrial enterprises, meteorological factors, and air quality. The meteorological conditions are fully utilized to dynamically adjust the exhaust gas emissions of key polluting enterprises. It not only ensures that the regional air quality is in good condition, but also promotes the in-depth optimization of the procedures of regional industrial enterprises, and reduces the conflict between environmental protection and economic development.},
	language = {en},
	number = {1},
	urldate = {2024-01-14},
	journal = {Scientific Reports},
	author = {Liu, Ying and Wang, Peiyu and Li, Yong and Wen, Lixia and Deng, Xiaochao},
	month = {jun},
	year = {2022},
	keywords = {Computational science, Environmental impact, Environmental sciences},
	pages = {9253},
}

@article{bai_air_2018,
	title = {Air {Pollution} {Forecasts}: {An} {Overview}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1660-4601},
	shorttitle = {Air {Pollution} {Forecasts}},
	url = {https://www.mdpi.com/1660-4601/15/4/780},
	doi = {10.3390/ijerph15040780},
	abstract = {Air pollution is defined as a phenomenon harmful to the ecological system and the normal conditions of human existence and development when some substances in the atmosphere exceed a certain concentration. In the face of increasingly serious environmental pollution problems, scholars have conducted a significant quantity of related research, and in those studies, the forecasting of air pollution has been of paramount importance. As a precaution, the air pollution forecast is the basis for taking effective pollution control measures, and accurate forecasting of air pollution has become an important task. Extensive research indicates that the methods of air pollution forecasting can be broadly divided into three classical categories: statistical forecasting methods, artificial intelligence methods, and numerical forecasting methods. More recently, some hybrid models have been proposed, which can improve the forecast accuracy. To provide a clear perspective on air pollution forecasting, this study reviews the theory and application of those forecasting models. In addition, based on a comparison of different forecasting methods, the advantages and disadvantages of some methods of forecasting are also provided. This study aims to provide an overview of air pollution forecasting methods for easy access and reference by researchers, which will be helpful in further studies.},
	language = {en},
	number = {4},
	urldate = {2024-01-14},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Bai, Lu and Wang, Jianzhou and Ma, Xuejiao and Lu, Haiyan},
	month = {apr},
	year = {2018},
	keywords = {air pollution forecast, forecasting models, statistical methods, artificial intelligence methods, numerical forecast methods, hybrid models},
	pages = {780},
}

@article{masood_review_2021,
	title = {A review on emerging artificial intelligence ({AI}) techniques for air pollution forecasting: {Fundamentals}, application and performance},
	volume = {322},
	issn = {0959-6526},
	shorttitle = {A review on emerging artificial intelligence ({AI}) techniques for air pollution forecasting},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652621032613},
	doi = {10.1016/j.jclepro.2021.129072},
	abstract = {Accurate air quality forecasting is critical for systematic pollution control as well as public health and wellness. Most of the traditional forecasting techniques have shown inconsistent predictive accuracy due to the non-linear, dynamic and complex nature of air pollutants. In the past few years, artificial intelligence (AI)-based methods have become the most powerful and forward-looking approaches for air pollution forecasting because of their specific features such as organic learning, high precision, superior generalization, strong fault tolerance, and ease of working with high-dimensional data. This study presents a comprehensive overview of the most widely used AI-based techniques for air pollution forecasting namely Artificial Neural Networks (ANN), Deep Neural Network (DNN), Support vector machine (SVM) and Fuzzy logic through a systematic literature review (SLR). In total 90 papers were selected which were distributed between 2003 and 2021. The SLR aims to classify the literature on AI-based air pollution forecasting from various perspectives, such as input parameters, relative frequency of application of AI techniques, performance, year of publication, journal and geographic distribution and also addresses the corresponding research questions related to this domain. The results showed that the number of citations and publications have been increasing in recent years. The most frequently applied input parameter is the air quality and the best performing AI-based technique is the DNN. On the other hand, Fuzzy logic, DNN and SVM are the three commonly used AI-based techniques for air pollution forecasting. In addition, some technological gaps in the literature and the pros and cons associated with the different AI techniques, were identified and discussed. This review article shows that AI-based techniques have triggered a resurgence of interest in air pollution forecasting and offer great potential to fundamentally change the way air pollution is forecasted in the near future.},
	urldate = {2024-01-14},
	journal = {Journal of Cleaner Production},
	author = {Masood, Adil and Ahmad, Kafeel},
	month = {nov},
	year = {2021},
	keywords = {Air pollution, Artificial neural networks, Deep neural networks, Relative frequency, Fuzzy logic, Support vector machine, Systematic literature review},
	pages = {129072},
}

@article{diaz-robles_hybrid_2008,
	title = {A hybrid {ARIMA} and artificial neural networks model to forecast particulate matter in urban areas: {The} case of {Temuco}, {Chile}},
	volume = {42},
	issn = {1352-2310},
	shorttitle = {A hybrid {ARIMA} and artificial neural networks model to forecast particulate matter in urban areas},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231008006523},
	doi = {10.1016/j.atmosenv.2008.07.020},
	abstract = {Air quality time series consists of complex linear and non-linear patterns and are difficult to forecast. Box–Jenkins Time Series (ARIMA) and multilinear regression (MLR) models have been applied to air quality forecasting in urban areas, but they have limited accuracy owing to their inability to predict extreme events. Artificial neural networks (ANN) can recognize non-linear patterns that include extremes. A novel hybrid model combining ARIMA and ANN to improve forecast accuracy for an area with limited air quality and meteorological data was applied to Temuco, Chile, where residential wood burning is a major pollution source during cold winters, using surface meteorological and PM10 measurements. Experimental results indicated that the hybrid model can be an effective tool to improve the PM10 forecasting accuracy obtained by either of the models used separately, and compared with a deterministic MLR. The hybrid model was able to capture 100\% and 80\% of alert and pre-emergency episodes, respectively. This approach demonstrates the potential to be applied to air quality forecasting in other cities and countries.},
	number = {35},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Díaz-Robles, Luis A. and Ortega, Juan C. and Fu, Joshua S. and Reed, Gregory D. and Chow, Judith C. and Watson, John G. and Moncada-Herrera, Juan A.},
	month = {nov},
	year = {2008},
	keywords = {Particulate matter forecasting, Hybrid, ARIMA, Neural networks, Temuco},
	pages = {8331--8340},
}

@article{garcia_nieto_svm-based_2013,
	title = {A {SVM}-based regression model to study the air quality at local scale in {Oviedo} urban area ({Northern} {Spain}): {A} case study},
	volume = {219},
	issn = {0096-3003},
	shorttitle = {A {SVM}-based regression model to study the air quality at local scale in {Oviedo} urban area ({Northern} {Spain})},
	url = {https://www.sciencedirect.com/science/article/pii/S0096300313002713},
	doi = {10.1016/j.amc.2013.03.018},
	abstract = {This research work presents a method of daily air pollution modeling by using support vector machine (SVM) technique in Oviedo urban area (Northern Spain) at local scale. Hazardous air pollutants or toxic air contaminants refer to any substances that may cause or contribute to an increase in mortality or in serious illness, or that may pose a present or potential hazard to human health. In this work, based on the observed data of NO, NO2, CO, SO2, O3 and dust (PM10) for the years 2006, 2007 and 2008, the support vector regression (SVR) technique is used to build the nonlinear dynamic model of the air quality in the urban area of the city of Oviedo (Spain). One main aim of this model was to make an initial preliminary estimate of the dependence between primary and secondary pollutants in the city of Oviedo. A second main aim was to determine the factors with the greatest bearing on air quality with a view to proposing health and lifestyle improvements. It is well-known that the United States National Ambient Air Quality Standards (NAAQS) establishes the limit values of the main pollutants in the atmosphere in order to ensure the health of healthy people. They are known as the criteria pollutants. This SVR fit captures the prime idea of statistical learning theory in order to obtain a good forecasting of the dependence among the main pollutants in the city of Oviedo. Finally, on the basis of these numerical calculations using SVR technique, from the experimental data, conclusions of this study are exposed.},
	number = {17},
	urldate = {2024-01-14},
	journal = {Applied Mathematics and Computation},
	author = {García Nieto, P. J. and Combarro, E. F. and del Coz Díaz, J. J. and Montañés, E.},
	month = {may},
	year = {2013},
	keywords = {Air quality, Pollutant substances, Machine learning, Support vector regression},
	pages = {8923--8937},
}

@article{yeganeh_prediction_2012,
	title = {Prediction of {CO} concentrations based on a hybrid {Partial} {Least} {Square} and {Support} {Vector} {Machine} model},
	volume = {55},
	issn = {1352-2310},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231012002300},
	doi = {10.1016/j.atmosenv.2012.02.092},
	abstract = {Due to the health impacts caused by exposures to air pollutants in urban areas, monitoring and forecasting of air quality parameters have become popular as an important topic in atmospheric and environmental research today. The knowledge on the dynamics and complexity of air pollutants behavior has made artificial intelligence models as a useful tool for a more accurate pollutant concentration prediction. This paper focuses on an innovative method of daily air pollution prediction using combination of Support Vector Machine (SVM) as predictor and Partial Least Square (PLS) as a data selection tool based on the measured values of CO concentrations. The CO concentrations of Rey monitoring station in the south of Tehran, from Jan. 2007 to Feb. 2011, have been used to test the effectiveness of this method. The hourly CO concentrations have been predicted using the SVM and the hybrid PLS–SVM models. Similarly, daily CO concentrations have been predicted based on the aforementioned four years measured data. Results demonstrated that both models have good prediction ability; however the hybrid PLS–SVM has better accuracy. In the analysis presented in this paper, statistic estimators including relative mean errors, root mean squared errors and the mean absolute relative error have been employed to compare performances of the models. It has been concluded that the errors decrease after size reduction and coefficients of determination increase from 56 to 81\% for SVM model to 65–85\% for hybrid PLS–SVM model respectively. Also it was found that the hybrid PLS–SVM model required lower computational time than SVM model as expected, hence supporting the more accurate and faster prediction ability of hybrid PLS–SVM model.},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Yeganeh, B. and Motlagh, M. Shafie Pour and Rashidi, Y. and Kamalan, H.},
	month = {aug},
	year = {2012},
	keywords = {CO concentration, Machine learning, Support Vector Machine, Partial Least Square, Hybrid models},
	pages = {357--365},
}

@article{singh_predicting_2013,
	title = {Predicting adsorptive removal of chlorophenol from aqueous solution using artificial intelligence based modeling approaches},
	volume = {20},
	issn = {1614-7499},
	url = {https://doi.org/10.1007/s11356-012-1102-y},
	doi = {10.1007/s11356-012-1102-y},
	abstract = {The research aims to develop artificial intelligence (AI)-based model to predict the adsorptive removal of 2-chlorophenol (CP) in aqueous solution by coconut shell carbon (CSC) using four operational variables (pH of solution, adsorbate concentration, temperature, and contact time), and to investigate their effects on the adsorption process. Accordingly, based on a factorial design, 640 batch experiments were conducted. Nonlinearities in experimental data were checked using Brock–Dechert–Scheimkman (BDS) statistics. Five nonlinear models were constructed to predict the adsorptive removal of CP in aqueous solution by CSC using four variables as input. Performances of the constructed models were evaluated and compared using statistical criteria. BDS statistics revealed strong nonlinearity in experimental data. Performance of all the models constructed here was satisfactory. Radial basis function network (RBFN) and multilayer perceptron network (MLPN) models performed better than generalized regression neural network, support vector machines, and gene expression programming models. Sensitivity analysis revealed that the contact time had highest effect on adsorption followed by the solution pH, temperature, and CP concentration. The study concluded that all the models constructed here were capable of capturing the nonlinearity in data. A better generalization and predictive performance of RBFN and MLPN models suggested that these can be used to predict the adsorption of CP in aqueous solution using CSC.},
	language = {en},
	number = {4},
	urldate = {2024-01-14},
	journal = {Environmental Science and Pollution Research},
	author = {Singh, Kunwar P. and Gupta, Shikha and Ojha, Priyanka and Rai, Premanjali},
	month = {apr},
	year = {2013},
	keywords = {Artificial intelligence, Nonlinear models, Artificial neural networks, Support vector machines, Gene expression programming, Adsorptive removal efficiency},
	pages = {2271--2287},
}

@article{thongthammachart_integrated_2021,
	title = {An integrated model combining random forests and {WRF}/{CMAQ} model for high accuracy spatiotemporal {PM2}.5 predictions in the {Kansai} region of {Japan}},
	volume = {262},
	issn = {1352-2310},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231021004428},
	doi = {10.1016/j.atmosenv.2021.118620},
	abstract = {Accurate spatial and temporal prediction of PM2.5 ambient concentration is crucial to appropriate exposure assessment. We develop a spatiotemporal land use regression model by integrating a random forests (RF) technique and the Community Multiscale Air Quality (CMAQ) modeling system to accurately estimate daily PM2.5 levels in the Kansai region of Japan, which is affected by long-range transport in the Asian continent and by local pollution. The most important advantage of RF is that it captures nonlinearity among the target air pollutants and the predictor variables including land-use variables, meteorological variables, and CMAQ-estimated PM2.5 concentration. We compare the predicting performances of the land use random forests (LURF) models with and without CMAQ variables to determine their effectiveness. A cross-validation (CV) technique that calculates the coefficient of determination (R2) and root mean square error (RMSE) is performed to evaluate their prediction performances through spatial and temporal CVs. The performance of the with-CMAQ LURF model was superior to that of the without-CMAQ LURF model. Moreover, we evaluated the PM2.5 prediction performances of the with-CMAQ LURF and the with-CMAQ land use linear regression (LULR) models via CV to determine the efficiency of the non-linear model. Accordingly, the with-CMAQ LURF model is preferable for PM2.5 estimation compared to that of the with-CMAQ LULR model. In addition, the with-CMAQ LURF model exhibits higher PM2.5 predictability than the CMAQ model, as indicated by the higher model-R2 and lower model-RMSE values. Our findings demonstrate that the CMAQ-simulated PM2.5 level integrated into the LURF is advantageous in accurately estimating PM2.5 concentration, which is influenced by long-range transport and local pollution.},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Thongthammachart, Tin and Araki, Shin and Shimadera, Hikari and Eto, Shinnosuke and Matsuo, Tomohito and Kondo, Akira},
	month = {oct},
	year = {2021},
	keywords = {Air pollution, Chemical transport model, Random forests, Land use regression},
	pages = {118620},
}

@article{ma_time_2022,
	title = {Time series-based {PM2}.5 concentration prediction in {Jing}-{Jin}-{Ji} area using machine learning algorithm models},
	volume = {8},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S240584402201979X},
	doi = {10.1016/j.heliyon.2022.e10691},
	abstract = {Globally all countries encounter air pollution problems along their development path. As a significant indicator of air quality, PM2.5 concentration has long been proven to be affecting the population’s death rate. Machine learning algorithms proven to outperform traditional statistical approaches are widely used in air pollution prediction. However research on the model selection discussion and environmental interpretation of model prediction results is still scarce and urgently needed to lead the policy making on air pollution control. Our research compared four types of machine learning algorisms LinearSVR, K-Nearest Neighbor, Lasso regression, Gradient boosting by looking into their performance in predicting PM2.5 concentrations among different cities and seasons. The results show that the machine learning model is able to forecast the next day PM2.5 concentration based on the previous five days' data with better accuracy. The comparative experiments show that based on city level the Gradient Boosting prediction model has better prediction performance with mean absolute error (MAE) of 9 ug/m3 and root mean square error (RMSE) of 10.25–16.76 ug/m3, lower compared with the other three models, and based on season level four models have the best prediction performances in winter time and the worst in summer time. And more importantly the demonstration of models' different performances in each city and each season is of great significance in environmental policy implications.},
	number = {9},
	urldate = {2024-01-14},
	journal = {Heliyon},
	author = {Ma, Xin and Chen, Tengfei and Ge, Rubing and Cui, Caocao and Xu, Fan and Lv, Qi},
	month = {sep},
	year = {2022},
	keywords = {Jing-Jin-Ji city group, PM prediction, Lasso regression, Gradient boosting, Linear SVR, K-Nearest Neighbor},
	pages = {e10691},
}

@article{singh_linear_2012,
	title = {Linear and nonlinear modeling approaches for urban air quality prediction},
	volume = {426},
	issn = {0048-9697},
	url = {https://www.sciencedirect.com/science/article/pii/S0048969712004809},
	doi = {10.1016/j.scitotenv.2012.03.076},
	abstract = {In this study, linear and nonlinear modeling was performed to predict the urban air quality of the Lucknow city (India). Partial least squares regression (PLSR), multivariate polynomial regression (MPR), and artificial neural network (ANN) approach-based models were constructed to predict the respirable suspended particulate matter (RSPM), SO2, and NO2 in the air using the meteorological (air temperature, relative humidity, wind speed) and air quality monitoring data (SPM, NO2, SO2) of five years (2005–2009). Three different ANN models, viz. multilayer perceptron network (MLPN), radial-basis function network (RBFN), and generalized regression neural network (GRNN) were developed. All the five different models were compared for their generalization and prediction abilities using statistical criteria parameters, viz. correlation coefficient (R), standard error of prediction (SEP), mean absolute error (MAE), root mean squared error (RMSE), bias, accuracy factor (Af), and Nash–Sutcliffe coefficient of efficiency (Ef). Nonlinear models (MPR, ANNs) performed relatively better than the linear PLSR models, whereas, performance of the ANN models was better than the low-order nonlinear MPR models. Although, performance of all the three ANN models were comparable, the GRNN over performed the other two variants. The optimal GRNN models for RSPM, NO2, and SO2 yielded high correlation (between measured and model predicted values) of 0.933, 0.893, and 0.885; 0.833, 0.602, and 0.596; and 0.932, 0.768 and 0.729, respectively for the training, validation and test sets. The sensitivity analysis performed to evaluate the importance of the input variables in optimal GRNN revealed that SO2 was the most influencing parameter in RSPM model, whereas, SPM was the most important input variable in other two models. The ANN models may be useful tools in the air quality predictions.},
	urldate = {2024-01-14},
	journal = {Science of The Total Environment},
	author = {Singh, Kunwar P. and Gupta, Shikha and Kumar, Atulesh and Shukla, Sheo Prasad},
	month = {jun},
	year = {2012},
	keywords = {Air quality, Partial least squares, Multivariate polynomial regression, Multilayer perceptron network, Radial basis function network, Generalized regression neural network},
	pages = {244--255},
}

@article{masood_review_2021-1,
	title = {A review on emerging artificial intelligence ({AI}) techniques for air pollution forecasting: {Fundamentals}, application and performance},
	volume = {322},
	issn = {0959-6526},
	shorttitle = {A review on emerging artificial intelligence ({AI}) techniques for air pollution forecasting},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652621032613},
	doi = {10.1016/j.jclepro.2021.129072},
	abstract = {Accurate air quality forecasting is critical for systematic pollution control as well as public health and wellness. Most of the traditional forecasting techniques have shown inconsistent predictive accuracy due to the non-linear, dynamic and complex nature of air pollutants. In the past few years, artificial intelligence (AI)-based methods have become the most powerful and forward-looking approaches for air pollution forecasting because of their specific features such as organic learning, high precision, superior generalization, strong fault tolerance, and ease of working with high-dimensional data. This study presents a comprehensive overview of the most widely used AI-based techniques for air pollution forecasting namely Artificial Neural Networks (ANN), Deep Neural Network (DNN), Support vector machine (SVM) and Fuzzy logic through a systematic literature review (SLR). In total 90 papers were selected which were distributed between 2003 and 2021. The SLR aims to classify the literature on AI-based air pollution forecasting from various perspectives, such as input parameters, relative frequency of application of AI techniques, performance, year of publication, journal and geographic distribution and also addresses the corresponding research questions related to this domain. The results showed that the number of citations and publications have been increasing in recent years. The most frequently applied input parameter is the air quality and the best performing AI-based technique is the DNN. On the other hand, Fuzzy logic, DNN and SVM are the three commonly used AI-based techniques for air pollution forecasting. In addition, some technological gaps in the literature and the pros and cons associated with the different AI techniques, were identified and discussed. This review article shows that AI-based techniques have triggered a resurgence of interest in air pollution forecasting and offer great potential to fundamentally change the way air pollution is forecasted in the near future.},
	urldate = {2024-01-14},
	journal = {Journal of Cleaner Production},
	author = {Masood, Adil and Ahmad, Kafeel},
	month = {nov},
	year = {2021},
	keywords = {Air pollution, Artificial neural networks, Deep neural networks, Relative frequency, Fuzzy logic, Support vector machine, Systematic literature review},
	pages = {129072},
}


@article{singh_identifying_2013,
	title = {Identifying pollution sources and predicting urban air quality using ensemble learning methods},
	volume = {80},
	issn = {1352-2310},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231013006328},
	doi = {10.1016/j.atmosenv.2013.08.023},
	abstract = {In this study, principal components analysis (PCA) was performed to identify air pollution sources and tree based ensemble learning models were constructed to predict the urban air quality of Lucknow (India) using the air quality and meteorological databases pertaining to a period of five years. PCA identified vehicular emissions and fuel combustion as major air pollution sources. The air quality indices revealed the air quality unhealthy during the summer and winter. Ensemble models were constructed to discriminate between the seasonal air qualities, factors responsible for discrimination, and to predict the air quality indices. Accordingly, single decision tree (SDT), decision tree forest (DTF), and decision treeboost (DTB) were constructed and their generalization and predictive performance was evaluated in terms of several statistical parameters and compared with conventional machine learning benchmark, support vector machines (SVM). The DT and SVM models discriminated the seasonal air quality rendering misclassification rate (MR) of 8.32\% (SDT); 4.12\% (DTF); 5.62\% (DTB), and 6.18\% (SVM), respectively in complete data. The AQI and CAQI regression models yielded a correlation between measured and predicted values and root mean squared error of 0.901, 6.67 and 0.825, 9.45 (SDT); 0.951, 4.85 and 0.922, 6.56 (DTF); 0.959, 4.38 and 0.929, 6.30 (DTB); 0.890, 7.00 and 0.836, 9.16 (SVR) in complete data. The DTF and DTB models outperformed the SVM both in classification and regression which could be attributed to the incorporation of the bagging and boosting algorithms in these models. The proposed ensemble models successfully predicted the urban ambient air quality and can be used as effective tools for its management.},
	urldate = {2024-01-14},
	journal = {Atmospheric Environment},
	author = {Singh, Kunwar P. and Gupta, Shikha and Rai, Premanjali},
	month = {dec},
	year = {2013},
	keywords = {Ensemble learning, Decision tree forest, Decision treeboost, Air quality, Indices, Air pollution, Seasonal discrimination},
	pages = {426--437},
}

@misc{noauthor_cams_nodate,
	title = {The {CAMS} {European} air quality ensemble forecasts welcomes two new state-of-the-art models {\textbar} {Copernicus}},
	url = {https://atmosphere.copernicus.eu/cams-european-air-quality-ensemble-forecasts-welcomes-two-new-state-art-models},
	urldate = {2024-01-14},
}

@article{de_medrano_socaire:_2021,
	title = {{SOCAIRE}: {Forecasting} and monitoring urban air quality in {Madrid}},
	volume = {143},
	issn = {1364-8152},
	shorttitle = {{SOCAIRE}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364815221001274},
	doi = {10.1016/j.envsoft.2021.105084},
	abstract = {Air quality has become a central issue in public health and urban planning management, due to the proven adverse effects of airborne pollutants. Considering temporary mobility restriction measures used to face low air quality episodes, the capability of foreseeing pollutant concentrations is crucial. We thus present SOCAIRE (Spanish acronim for “operational forecast system for air quality”), an operational tool based on a Bayesian and spatiotemporal ensemble of neural and statistical nested models. SOCAIRE integrates endogenous and exogenous information in order to predict and monitor future distributions of the concentration for the main pollutants. It focuses on modeling available components which affect air quality: past concentrations of pollutants, human activity, and numerical pollution and weather predictions. This tool is currently in operation in Madrid, producing daily air quality predictions for the next 48 h and anticipating the probability of the activation of the measures included in the city's official air quality NO2 protocols through probabilistic inferences about compound events.},
	urldate = {2024-01-14},
	journal = {Environmental Modelling \& Software},
	author = {de Medrano, Rodrigo and de Buen Remiro, Víctor and Aznarte, José L.},
	month = {sep},
	year = {2021},
	keywords = {Air quality, Spatio-temporal series, Statistical modeling, Neural networks},
	pages = {105084},
}

@article{cordero_true_2022,
	title = {True {Reduction} in the {Air} {Pollution} {Levels} in the {Community} of {Madrid} {During} the {COVID}-19 {Lockdown}},
	volume = {4},
	issn = {2624-9634},
	url = {https://www.frontiersin.org/articles/10.3389/frsc.2022.869000},
	abstract = {The coronavirus disease (COVID) lockdown was implemented in 2020, which included harsh restrictions on the amount of traffic. As a consequence, a low-emission scenario that could only be simulated before, actually occurred. This constituted a unique and valuable opportunity to study the effect of air quality pollutant concentrations. Although a direct comparison between the observed measured values given by reference air quality stations (AQSs) and values from before the COVID lockdown provides an idea of the pollution reduction, it cannot be separated from the meteorology, and hence, those studies could be misleading. This study used the approach of modeling a normal business day using both air quality and meteorological data from 2017 to 2019 to train machine-learning models to be able to predict what concentration of the three most concerning pollutants (NO2, O3, and PM10) would be given by the meteorological conditions and the time of the year. The XGBoost and LightGBM gradient boosting decision tree-based models were applied to the time series recorded in Madrid and used to predict the expected concentrations in 2020 if no restrictions had been made. The predictions could then be compared to the real observed AQS data to determine the meteorological normalized reductions. The results showed around a 60\% reduction in the NO2 at the three types of AQSs (traffic, suburban, and background) during the most restrictive months of the pandemic. The O3 concentration showed a different behavior depending on the type of AQS, pointing to changes in the regime of other pollutants, such as VOCs. The PM10 was the most difficult case to analyze because of its dependence on external transport phenomena, which were difficult to consider in the models. A set of CTM simulations should be done in the future to assess the O3-VOCs-NOx chemistry.},
	urldate = {2024-01-14},
	journal = {Frontiers in Sustainable Cities},
	author = {Cordero, Jose María and Narros, Adolfo and Borge, Rafael},
	year = {2022},
}

@inproceedings{pardo_air_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Air {Quality} {Forecasting} in {Madrid} {Using} {Long} {Short}-{Term} {Memory} {Networks}},
	isbn = {9783319597737},
	doi = {10.1007/978-3-319-59773-7_24},
	abstract = {},
	language = {en},
	booktitle = {Biomedical {Applications} {Based} on {Natural} and {Artificial} {Computing}},
	publisher = {Springer International Publishing},
	author = {Pardo, Esteban and Malpica, Norberto},
	editor = {Ferrández Vicente, José Manuel and Álvarez-Sánchez, José Ramón and de la Paz López, Félix and Toledo Moreo, Javier and Adeli, Hojjat},
	year = {2017},
	keywords = {Air quality forecasting, Long short-term memory},
	pages = {232--239},
}

@inproceedings{alhirmizy_multivariate_2019,
	title = {Multivariate {Time} {Series} {Forecasting} with {LSTM} for {Madrid}, {Spain} pollution},
	url = {https://ieeexplore.ieee.org/document/8830667},
	doi = {10.1109/ICCISTA.2019.8830667},
	abstract = {Time series forecasting is something of a dark horse in the field of data science and it is most critical factor that decides whether a business, temperatures or any environmental factors effect will rise or fall, A single time-dependent variable means A univariate time series while A Multivariate time series like environmental data has more than one time-dependent variable. Each variable depends on its past values and also on other variables past values. this paper used Neural networks like Long Short-Term Memory (LSTM) for forecasting Spain capital Madrid Air Quality using a dataset that reports on the weather and the level of pollution each hour for two years from 2015to 2016 the data includes the date-time, the pollution concentration of the following: SO2, NO\_2, NO, CO. Almost the best problems modelling for multiple input variables are recurrent neural networks and they are the great solution for multiple input time series forecasting problems, where classical linear methods can't. this paper used LSTM model for multivariate time series forecasting in the Keras and Tensor Flow deep learning library in a Python SciPy environment with Machine Learning scikit-learn, Pandas, NumPy and Matplotlib libraries.},
	urldate = {2024-01-14},
	booktitle = {2019 {International} {Conference} on {Computing} and {Information} {Science} and {Technology} and {Their} {Applications} ({ICCISTA})},
	author = {Alhirmizy, Shaheen and Qader, Banaz},
	month = {mar},
	year = {2019},
	pages = {1--5},
}

@article{soh_adaptive_2018,
	title = {Adaptive {Deep} {Learning}-{Based} {Air} {Quality} {Prediction} {Model} {Using} the {Most} {Relevant} {Spatial}-{Temporal} {Relations}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8392677},
	doi = {10.1109/ACCESS.2018.2849820},
	abstract = {Air pollution has become an extremely serious problem, with particulate matter having a significantly greater impact on human health than other contaminants. The small diameter of fine particulate matter (PM2.5) allows it to penetrate deep into the alveoli as far as the bronchioles, interfering with a gas exchange within the lungs. Long-term exposure to particulate matter has been shown to cause the cardiovascular disease, respiratory disease, and increase the risk of lung cancers. Therefore, forecasting air quality has also become important to help guide individual actions. This paper aims to forecast air quality for up to 48 h using a combination of multiple neural networks, including an artificial neural network, a convolutional neural network, and a long-short-term memory to extract spatial-temporal relations. The proposed predictive model considers various meteorology data from the previous few hours as well as information related to the elevation space to extract terrain impact on air quality. The model includes trends from multiple locations, extracted from correlations between adjacent locations, and among similar locations in the temporal domain. Experiments employing Taiwan and Beijing data sets show that the proposed model achieves excellent performance and outperforms current state-of-the-art methods.},
	urldate = {2024-01-14},
	journal = {IEEE Access},
	author = {Soh, Ping-Wei and Chang, Jia-Wei and Huang, Jen-Wei},
	year = {2018},
	pages = {38186--38199},
}


@article{gardner-frolick_selecting_2022,
	title = {Selecting {Data} {Analytic} and {Modeling} {Methods} to {Support} {Air} {Pollution} and {Environmental} {Justice} {Investigations}: {A} {Critical} {Review} and {Guidance} {Framework}},
	volume = {56},
	issn = {0013-936X, 1520-5851},
	shorttitle = {Selecting {Data} {Analytic} and {Modeling} {Methods} to {Support} {Air} {Pollution} and {Environmental} {Justice} {Investigations}},
	url = {https://pubs.acs.org/doi/10.1021/acs.est.1c01739},
	doi = {10.1021/acs.est.1c01739},
	language = {en},
	number = {5},
	urldate = {2024-01-21},
	journal = {Environmental Science \& Technology},
	author = {Gardner-Frolick, Rivkah and Boyd, David and Giang, Amanda},
	month = {mar},
	year = {2022},
	pages = {2843--2860},
}

@article{carbajal-hernandez_assessment_2012,
	title = {Assessment and prediction of air quality using fuzzy logic and autoregressive models},
	volume = {60},
	issn = {1352-2310},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231012005341},
	doi = {10.1016/j.atmosenv.2012.06.004},
	abstract = {In recent years, artificial intelligence methods have been used for the treatment of environmental problems. This work, presents two models for assessment and prediction of air quality. First, we develop a new computational model for air quality assessment in order to evaluate toxic compounds that can harm sensitive people in urban areas, affecting their normal activities. In this model we propose to use a Sigma operator to statistically asses air quality parameters using their historical data information and determining their negative impact in air quality based on toxicity limits, frequency average and deviations of toxicological tests. We also introduce a fuzzy inference system to perform parameter classification using a reasoning process and integrating them in an air quality index describing the pollution levels in five stages: excellent, good, regular, bad and danger, respectively. The second model proposed in this work predicts air quality concentrations using an autoregressive model, providing a predicted air quality index based on the fuzzy inference system previously developed. Using data from Mexico City Atmospheric Monitoring System, we perform a comparison among air quality indices developed for environmental agencies and similar models. Our results show that our models are an appropriate tool for assessing site pollution and for providing guidance to improve contingency actions in urban areas.},
	urldate = {2024-01-28},
	journal = {Atmospheric Environment},
	author = {Carbajal-Hernández, José Juan and Sánchez-Fernández, Luis P. and Carrasco-Ochoa, Jesús A. and Martínez-Trinidad, José Fco.},
	month = {dec},
	year = {2012},
	keywords = {Artificial intelligence, Air quality assessment, Pattern processing, Prediction},
	pages = {37--50},
}
@article{de_medrano_socaire_2021,
	title = {{SOCAIRE}: {Forecasting} and monitoring urban air quality in {Madrid}},
	volume = {143},
	issn = {1364-8152},
	shorttitle = {{SOCAIRE}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364815221001274},
	doi = {10.1016/j.envsoft.2021.105084},
	abstract = {Air quality has become a central issue in public health and urban planning management, due to the proven adverse effects of airborne pollutants. Considering temporary mobility restriction measures used to face low air quality episodes, the capability of foreseeing pollutant concentrations is crucial. We thus present SOCAIRE (Spanish acronim for “operational forecast system for air quality”), an operational tool based on a Bayesian and spatiotemporal ensemble of neural and statistical nested models. SOCAIRE integrates endogenous and exogenous information in order to predict and monitor future distributions of the concentration for the main pollutants. It focuses on modeling available components which affect air quality: past concentrations of pollutants, human activity, and numerical pollution and weather predictions. This tool is currently in operation in Madrid, producing daily air quality predictions for the next 48 h and anticipating the probability of the activation of the measures included in the city's official air quality NO2 protocols through probabilistic inferences about compound events.},
	urldate = {2024-01-28},
	journal = {Environmental Modelling \& Software},
	author = {de Medrano, Rodrigo and de Buen Remiro, Víctor and Aznarte, José L.},
	month = {sep},
	year = {2021},
	keywords = {Air quality, Spatio-temporal series, Statistical modeling, Neural networks},
	pages = {105084},
}


@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2024-01-28},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = {nov},
	year = {1997},
	pages = {1735--1780},
}

@incollection{lecun_convolutional_1998,
	address = {Cambridge, MA, USA},
	title = {Convolutional networks for images, speech, and time series},
	isbn = {9780262511025},
	urldate = {2024-01-28},
	booktitle = {The handbook of brain theory and neural networks},
	publisher = {MIT Press},
	author = {LeCun, Yann and Bengio, Yoshua},
	month = {oct},
	year = {1998},
	pages = {255--258},
}


@article{cabaneros_methods_2022,
	title = {Methods used for handling and quantifying model uncertainty of artificial neural network models for air pollution forecasting},
	volume = {158},
	issn = {1364-8152},
	url = {https://www.sciencedirect.com/science/article/pii/S1364815222002298},
	doi = {10.1016/j.envsoft.2022.105529},
	abstract = {The use of data-driven techniques such as artificial neural network (ANN) models for outdoor air pollution forecasting has been popular in the past two decades. However, research activity on the uncertainty surrounding the development of ANN models has been limited. Therefore, this review outlines the approaches for addressing model uncertainty according to the steps for building ANN models. Based on 128 articles published from 2000 to 2022, the review reveals that input uncertainty was predominantly addressed while less focus was given to structure, parameter and output uncertainties. Ensemble approaches have been mostly employed, followed by neuro-fuzzy networks. However, the direct measurement of uncertainty received less attention. The use of bootstrapping, Bayesian, and Monte Carlo simulation techniques which can quantify uncertainty was also limited. In conclusion, this review recommends the development and application of approaches that can both handle and quantify uncertainty surrounding the development of ANN models.},
	urldate = {2024-02-07},
	journal = {Environmental Modelling \& Software},
	author = {Cabaneros, Sheen Mclean and Hughes, Ben},
	month = {dec},
	year = {2022},
	keywords = {Air pollution forecasting, Artificial neural networks, Uncertainty quantification, Bayesian, Monte Carlo simulation, Fuzzy},
	pages = {105529},
}

@article{hewamalage_global_2022,
	title = {Global models for time series forecasting: {A} {Simulation} study},
	volume = {124},
	issn = {0031-3203},
	shorttitle = {Global models for time series forecasting},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321006178},
	doi = {10.1016/j.patcog.2021.108441},
	abstract = {The recent advances in Big Data have opened up the opportunity to develop competitive Global Forecasting Models (GFM) that simultaneously learn from many time series. Although, the concept of series relatedness has been heavily exploited with GFMs to explain their superiority over local statistical benchmarks, this concept remains largely under-investigated in an empirical setting. Hence, this study attempts to explore the factors that affect GFM performance, by simulating a number of datasets having controllable characteristics. The factors being controlled are along the homogeneity/heterogeneity of series, the complexity of patterns in the series, the complexity of forecasting models, and the lengths/number of series. We simulate time series from simple Data Generating Processes (DGP), such as Auto Regressive (AR), Seasonal AR and Fourier Terms to complex DGPs, such as Chaotic Logistic Map, Self-Exciting Threshold Auto-Regressive and Mackey-Glass Equations. We perform experiments on these datasets using Recurrent Neural Networks (RNN), Feed-Forward Neural Networks, Pooled Regression models and Light Gradient Boosting Models (LGBM) built as GFMs, and compare their performance against standard statistical forecasting techniques. Our experiments demonstrate that with respect to GFM performance, relatedness is closely associated with other factors such as the availability of data, complexity of data and the complexity of the forecasting technique used. Also, techniques such as RNNs and LGBMs having complex non-linear modelling capabilities, when built as GFMs are competitive methods under challenging forecasting scenarios such as short series, heterogeneous series and having minimal prior knowledge of the data patterns.},
	urldate = {2024-02-09},
	journal = {Pattern Recognition},
	author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
	month = {apr},
	year = {2022},
	keywords = {Time series forecasting, Global forecasting models, Time series simulation, Data generating processes},
	pages = {108441},
}


@article{makridakis_m3-competition:_2000,
	series = {The {M3}- {Competition}},
	title = {The {M3}-{Competition}: results, conclusions and implications},
	volume = {16},
	issn = {0169-2070},
	shorttitle = {The {M3}-{Competition}},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207000000571},
	doi = {10.1016/S0169-2070(00)00057-1},
	abstract = {This paper describes the M3-Competition, the latest of the M-Competitions. It explains the reasons for conducting the competition and summarizes its results and conclusions. In addition, the paper compares such results/conclusions with those of the previous two M-Competitions as well as with those of other major empirical studies. Finally, the implications of these results and conclusions are considered, their consequences for both the theory and practice of forecasting are explored and directions for future research are contemplated.},
	number = {4},
	urldate = {2024-03-12},
	journal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Hibon, Michèle},
	month = {oct},
	year = {2000},
	keywords = {Comparative methods — time series: univariate, Forecasting competitions, M-Competition, Forecasting methods, Forecasting accuracy},
	pages = {451--476},
}

@article{makridakis_m4_2020,
	series = {M4 {Competition}},
	title = {The {M4} {Competition}: 100,000 time series and 61 forecasting methods},
	volume = {36},
	issn = {0169-2070},
	shorttitle = {The {M4} {Competition}},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207019301128},
	doi = {10.1016/j.ijforecast.2019.04.014},
	abstract = {The M4 Competition follows on from the three previous M competitions, the purpose of which was to learn from empirical evidence both how to improve the forecasting accuracy and how such learning could be used to advance the theory and practice of forecasting. The aim of M4 was to replicate and extend the three previous competitions by: (a) significantly increasing the number of series, (b) expanding the number of forecasting methods, and (c) including prediction intervals in the evaluation process as well as point forecasts. This paper covers all aspects of M4 in detail, including its organization and running, the presentation of its results, the top-performing methods overall and by categories, its major findings and their implications, and the computational requirements of the various methods. Finally, it summarizes its main conclusions and states the expectation that its series will become a testing ground for the evaluation of new methods and the improvement of the practice of forecasting, while also suggesting some ways forward for the field.},
	number = {1},
	urldate = {2024-03-12},
	journal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
	month = {jan},
	year = {2020},
	keywords = {Forecasting competitions, M competitions, Forecasting accuracy, Prediction intervals, Time series methods, Machine learning methods, Benchmarking methods, Practice of forecasting},
	pages = {54--74},
}

@article{makridakis_m5_2022,
	series = {Special {Issue}: {M5} competition},
	title = {M5 accuracy competition: {Results}, findings, and conclusions},
	volume = {38},
	issn = {0169-2070},
	shorttitle = {M5 accuracy competition},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001874},
	doi = {10.1016/j.ijforecast.2021.11.013},
	abstract = {In this study, we present the results of the M5 “Accuracy” competition, which was the first of two parallel challenges in the latest M competition with the aim of advancing the theory and practice of forecasting. The main objective in the M5 “Accuracy” competition was to accurately predict 42,840 time series representing the hierarchical unit sales for the largest retail company in the world by revenue, Walmart. The competition required the submission of 30,490 point forecasts for the lowest cross-sectional aggregation level of the data, which could then be summed up accordingly to estimate forecasts for the remaining upward levels. We provide details of the implementation of the M5 “Accuracy” challenge, as well as the results and best performing methods, and summarize the major findings and conclusions. Finally, we discuss the implications of these findings and suggest directions for future research.},
	number = {4},
	urldate = {2024-03-12},
	journal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
	month = {oct},
	year = {2022},
	keywords = {Forecasting competitions, M competitions, Accuracy, Time series, Machine learning, Retail sales forecasting},
	pages = {1346--1364},
}

@inproceedings{NIPS2017_6449f44a,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper\_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{peters_evaluating_2022,
	title = {Evaluating uncertainty in sensor networks for urban air pollution insights},
	volume = {15},
	issn = {1867-1381},
	url = {https://amt.copernicus.org/articles/15/321/2022/},
	doi = {10.5194/amt-15-321-2022},
	abstract = {Ambient air pollution poses a major global public health risk. Lower-cost air quality sensors (LCSs) are increasingly being explored as a tool to understand local air pollution problems and develop effective solutions. A barrier to LCS adoption is potentially larger measurement uncertainty compared to reference measurement technology. The technical performance of various LCSs has been tested in laboratory and field environments, and a growing body of literature on uses of LCSs primarily focuses on proof-of-concept deployments. However, few studies have demonstrated the implications of LCS measurement uncertainties on a sensor network's ability to assess spatiotemporal patterns of local air pollution. Here, we present results from a 2-year deployment of 100 stationary electrochemical nitrogen dioxide (NO2) LCSs across Greater London as part of the Breathe London pilot project (BL). We evaluated sensor performance using collocations with reference instruments, estimating ∼ 35 \% average uncertainty (root mean square error) in the calibrated LCSs, and identified infrequent, multi-week periods of poorer performance and high bias during summer months. We analyzed BL data to generate insights about London's air pollution, including long-term concentration trends, diurnal and day-of-week patterns, and profiles of elevated concentrations during regional pollution episodes. These findings were validated against measurements from an extensive reference network, demonstrating the BL network's ability to generate robust information about London's air pollution. In cases where the BL network did not effectively capture features that the reference network measured, ongoing collocations of representative sensors often provided evidence of irregularities in sensor performance, demonstrating how, in the absence of an extensive reference network, project-long collocations could enable characterization and mitigation of network-wide sensor uncertainties. The conclusions are restricted to the specific sensors used for this study, but the results give direction to LCS users by demonstrating the kinds of air pollution insights possible from LCS networks and provide a blueprint for future LCS projects to manage and evaluate uncertainties when collecting, analyzing, and interpreting data.},
	language = {English},
	number = {2},
	urldate = {2024-04-14},
	journal = {Atmospheric Measurement Techniques},
	author = {Peters, Daniel R. and Popoola, Olalekan A. M. and Jones, Roderic L. and Martin, Nicholas A. and Mills, Jim and Fonseca, Elizabeth R. and Stidworthy, Amy and Forsyth, Ella and Carruthers, David and Dupuy-Todd, Megan and Douglas, Felicia and Moore, Katie and Shah, Rishabh U. and Padilla, Lauren E. and Alvarez, Ramón A.},
	month = {jan},
	year = {2022},
	pages = {321--334},
}


@article{JMLR:v23:21-0888,
  author  = {Marius Lindauer and Katharina Eggensperger and Matthias Feurer and André Biedenkapp and Difan Deng and Carolin Benjamins and Tim Ruhkopf and René Sass and Frank Hutter},
  title   = {SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {54},
  pages   = {1--9},
  url     = {http://jmlr.org/papers/v23/21-0888.html}
}

@article{makridakis_statistical_2023,
	title = {Statistical, machine learning and deep learning forecasting methods: {Comparisons} and ways forward},
	volume = {74},
	issn = {0160-5682, 1476-9360},
	shorttitle = {Statistical, machine learning and deep learning forecasting methods},
	url = {https://www.tandfonline.com/doi/full/10.1080/01605682.2022.2118629},
	doi = {10.1080/01605682.2022.2118629},
	language = {en},
	number = {3},
	urldate = {2024-04-20},
	journal = {Journal of the Operational Research Society},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios and Semenoglou, Artemios-Anargyros and Mulder, Gary and Nikolopoulos, Konstantinos},
	month = {mar},
	year = {2023},
	pages = {840--859},
}


@article{lstmref,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@incollection{lecun_convolutional_1995,
	title = {Convolutional networks for images, speech, and time-series},
	booktitle = {The handbook of brain theory and neural networks},
	publisher = {MIT Press},
	author = {Lecun, Yann and Bengio, Yoshua},
	editor = {Arbib, M.A.},
	year = {1995},
}

@article{vasseur_comparing_2021,
	title = {Comparing quantile regression methods for probabilistic forecasting of {NO2} pollution levels},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-90063-3},
	doi = {10.1038/s41598-021-90063-3},
	abstract = {High concentration episodes for NO2 are increasingly dealt with by authorities through traffic restrictions which are activated when air quality deteriorates beyond certain thresholds. Foreseeing the probability that pollutant concentrations reach those thresholds becomes thus a necessity. Probabilistic forecasting, as oposed to point-forecasting, is a family of techniques that allow for the prediction of the expected distribution function instead of a single future value. In the case of NO2, it allows for the calculation of future chances of exceeding thresholds and to detect pollution peaks. However, there is a lack of comparative studies for probabilistic models in the field of air pollution. In this work, we thoroughly compared 10 state of the art quantile regression models, using them to predict the distribution of NO2 concentrations in a urban location for a set of forecasting horizons (up to 60 hours into the future). Instead of using directly the quantiles, we derived from them the parameters of a predicted distribution, rendering this method semi-parametric. Amongst the models tested, quantile gradient boosted trees show the best performance, yielding the best results for both expected point value and full distribution. However, we found the simpler quantile k-nearest neighbors combined with a linear regression provided similar results with much lower training time and complexity.},
	language = {en},
	number = {1},
	urldate = {2024-04-20},
	journal = {Scientific Reports},
	author = {Vasseur, Sebastien Pérez and Aznarte, José L.},
	month = {jun},
	year = {2021},
	keywords = {Environmental sciences, Mathematics and computing},
	pages = {11592},
}



@misc{marz_xgboostlss_2019,
	title = {{XGBoostLSS} -- {An} extension of {XGBoost} to probabilistic forecasting},
	url = {http://arxiv.org/abs/1907.03178},
	doi = {10.48550/arXiv.1907.03178},
	abstract = {We propose a new framework of XGBoost that predicts the entire conditional distribution of a univariate response variable. In particular, XGBoostLSS models all moments of a parametric distribution (i.e., mean, location, scale and shape [LSS]) instead of the conditional mean only. Choosing from a wide range of continuous, discrete and mixed discrete-continuous distribution, modelling and predicting the entire conditional distribution greatly enhances the flexibility of XGBoost, as it allows to gain additional insight into the data generating process, as well as to create probabilistic forecasts from which prediction intervals and quantiles of interest can be derived. We present both a simulation study and real world examples that demonstrate the virtues of our approach.},
	urldate = {2024-04-20},
	publisher = {arXiv},
	author = {März, Alexander},
	month = {aug},
	year = {2019},
	note = {arXiv:1907.03178 [cs, stat]},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Methodology},
}


@article{anderson_clearing_2012,
	title = {Clearing the {Air}: {A} {Review} of the {Effects} of {Particulate} {Matter} {Air} {Pollution} on {Human} {Health}},
	volume = {8},
	issn = {1556-9039},
	shorttitle = {Clearing the {Air}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3550231/},
	doi = {10.1007/s13181-011-0203-1},
	abstract = {The World Health Organization estimates that particulate matter (PM) air pollution contributes to approximately 800,000 premature deaths each year, ranking it the 13th leading cause of mortality worldwide. However, many studies show that the relationship is deeper and far more complicated than originally thought. PM is a portion of air pollution that is made up of extremely small particles and liquid droplets containing acids, organic chemicals, metals, and soil or dust particles. PM is categorized by size and continues to be the fraction of air pollution that is most reliably associated with human disease. PM is thought to contribute to cardiovascular and cerebrovascular disease by the mechanisms of systemic inflammation, direct and indirect coagulation activation, and direct translocation into systemic circulation. The data demonstrating PM's effect on the cardiovascular system are strong. Populations subjected to long-term exposure to PM have a significantly higher cardiovascular incident and mortality rate. Short-term acute exposures subtly increase the rate of cardiovascular events within days of a pollution spike. The data are not as strong for PM's effects on cerebrovascular disease, though some data and similar mechanisms suggest a lesser result with smaller amplitude. Respiratory diseases are also exacerbated by exposure to PM. PM causes respiratory morbidity and mortality by creating oxidative stress and inflammation that leads to pulmonary anatomic and physiologic remodeling. The literature shows PM causes worsening respiratory symptoms, more frequent medication use, decreased lung function, recurrent health care utilization, and increased mortality. PM exposure has been shown to have a small but significant adverse effect on cardiovascular, respiratory, and to a lesser extent, cerebrovascular disease. These consistent results are shown by multiple studies with varying populations, protocols, and regions. The data demonstrate a dose-dependent relationship between PM and human disease, and that removal from a PM-rich environment decreases the prevalence of these diseases. While further study is needed to elucidate the effects of composition, chemistry, and the PM effect on susceptible populations, the preponderance of data shows that PM exposure causes a small but significant increase in human morbidity and mortality. Most sources agree on certain “common sense” recommendations, although there are lonely limited data to support them. Indoor PM exposure can be reduced by the usage of air conditioning and particulate filters, decreasing indoor combustion for heating and cooking, and smoking cessation. Susceptible populations, such as the elderly or asthmatics, may benefit from limiting their outdoor activity during peak traffic periods or poor air quality days. These simple changes may benefit individual patients in both short-term symptomatic control and long-term cardiovascular and respiratory complications.},
	number = {2},
	urldate = {2024-04-20},
	journal = {Journal of Medical Toxicology},
	author = {Anderson, Jonathan O. and Thundiyil, Josef G. and Stolbach, Andrew},
	month = {jun},
	year = {2012},
	pmid = {22194192},
	pmcid = {PMC3550231},
	pages = {166--175},
}

@article{cleveland1990stl,
  title={STL: A seasonal-trend decomposition},
  author={Cleveland, Robert B and Cleveland, William S and McRae, Jean E and Terpenning, Irma and others},
  journal={J. Off. Stat},
  volume={6},
  number={1},
  pages={3--73},
  year={1990}
}
@inproceedings{
rasul2021multivariate,
title={Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows},
author={Kashif Rasul and Abdul-Saboor Sheikh and Ingmar Schuster and Urs M Bergmann and Roland Vollgraf},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=WiGQBFuVRv}
}


@misc{meteorologia_agencia_nodate,
	title = {Agencia {Estatal} de {Meteorología} - {AEMET}. {Gobierno} de {España}},
	url = {https://www.aemet.es/es/portada},
	abstract = {Información meteorológica y climatológica, predicción, avisos, observación, anuncios, atención al público, divulgación e información de la Agencia},
	language = {es},
	urldate = {2024-04-30},
	author = {Meteorología, Agencia Estatal de},
}


@misc{cams,
	title = {Copernicus Atmospheric Monitoring Services},
	url = {https://atmosphere.copernicus.eu/},
	urldate = {2024-04-30},
}




@article{hersbach_decomposition_2000,
	title = {Decomposition of the {Continuous} {Ranked} {Probability} {Score} for {Ensemble} {Prediction} {Systems}},
	volume = {15},
	issn = {0882-8156, 1520-0434},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0434(2000)015<0559:DOTCRP>2.0.CO;2},
	doi = {10.1175/1520-0434(2000)015<0559:DOTCRP>2.0.CO;2},
	language = {en},
	number = {5},
	urldate = {2024-05-12},
	journal = {Weather and Forecasting},
	author = {Hersbach, Hans},
	month = {oct},
	year = {2000},
	pages = {559--570},
}

@article{januschowski_criteria_2020,
	series = {M4 {Competition}},
	title = {Criteria for classifying forecasting methods},
	volume = {36},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207019301529},
	doi = {10.1016/j.ijforecast.2019.05.008},
	abstract = {Classifying forecasting methods as being either of a “machine learning” or “statistical” nature has become commonplace in parts of the forecasting literature and community, as exemplified by the M4 competition and the conclusion drawn by the organizers. We argue that this distinction does not stem from fundamental differences in the methods assigned to either class. Instead, this distinction is probably of a tribal nature, which limits the insights into the appropriateness and effectiveness of different forecasting methods. We provide alternative characteristics of forecasting methods which, in our view, allow to draw meaningful conclusions. Further, we discuss areas of forecasting which could benefit most from cross-pollination between the ML and the statistics communities.},
	number = {1},
	urldate = {2024-07-13},
	journal = {International Journal of Forecasting},
	author = {Januschowski, Tim and Gasthaus, Jan and Wang, Yuyang and Salinas, David and Flunkert, Valentin and Bohlke-Schneider, Michael and Callot, Laurent},
	month = {jan},
	year = {2020},
	pages = {167--177},
}

@misc{hewamalage_global_2021,
	title = {Global {Models} for {Time} {Series} {Forecasting}: {A} {Simulation} {Study}},
	shorttitle = {Global {Models} for {Time} {Series} {Forecasting}},
	url = {http://arxiv.org/abs/2012.12485},
	doi = {10.48550/arXiv.2012.12485},
	abstract = {In the current context of Big Data, the nature of many forecasting problems has changed from predicting isolated time series to predicting many time series from similar sources. This has opened up the opportunity to develop competitive global forecasting models that simultaneously learn from many time series. But, it still remains unclear when global forecasting models can outperform the univariate benchmarks, especially along the dimensions of the homogeneity/heterogeneity of series, the complexity of patterns in the series, the complexity of forecasting models, and the lengths/number of series. Our study attempts to address this problem through investigating the effect from these factors, by simulating a number of datasets that have controllable time series characteristics. Specifically, we simulate time series from simple data generating processes (DGP), such as Auto Regressive (AR) and Seasonal AR, to complex DGPs, such as Chaotic Logistic Map, Self-Exciting Threshold Auto-Regressive, and Mackey-Glass Equations. The data heterogeneity is introduced by mixing time series generated from several DGPs into a single dataset. The lengths and the number of series in the dataset are varied in different scenarios. We perform experiments on these datasets using global forecasting models including Recurrent Neural Networks (RNN), Feed-Forward Neural Networks, Pooled Regression (PR) models and Light Gradient Boosting Models (LGBM), and compare their performance against standard statistical univariate forecasting techniques. Our experiments demonstrate that when trained as global forecasting models, techniques such as RNNs and LGBMs, which have complex non-linear modelling capabilities, are competitive methods in general under challenging forecasting scenarios such as series having short lengths, datasets with heterogeneous series and having minimal prior knowledge of the patterns of the series.},
	urldate = {2024-07-13},
	publisher = {arXiv},
	author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
	month = {mar},
	year = {2021},
	note = {arXiv:2012.12485 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hewamalage_advancing_2022,
	title = {Advancing {Time} {Series} {Forecasting} {Techniques} \&amp; {Practices} in a {Big} {Data} {Environment}},
	copyright = {In Copyright},
	url = {https://bridges.monash.edu/articles/thesis/Advancing\_Time\_Series\_Forecasting\_Techniques\_Practices\_in\_a\_Big\_Data\_Environment/18585446/1},
	doi = {10.26180/18585446.V1},
	abstract = {Accurate forecasting is pivotal to domains such as transportation, tourism, and energy. Although forecasting was traditionally limited to a few time series analysed by statisticians, the scale of the data collated has escalated rapidly in recent years. Consequently, while data scientists are becoming enthusiastic about applying Machine Learning (ML) techniques for forecasting, the details behind adapting them to forecasting remain lesser-known. This thesis addresses this overarching problem by 1) performing empirical analyses on the factors influencing the performance of ML models built as Global Forecasting Models (GFM) and 2) developing tools and guidelines to support forecast evaluation in many-series scenarios.},
	urldate = {2024-07-13},
	author = {Hewamalage, Hansika PEHESARANI},
	year = {2022},
	keywords = {Applied computing not elsewhere classified, Time-series analysis, Pattern recognition, Data mining and knowledge discovery},
	pages = {43488300 Bytes},
}

@article{bandara_forecasting_2020,
	title = {Forecasting across time series databases using recurrent neural networks on groups of similar series: {A} clustering approach},
	volume = {140},
	issn = {0957-4174},
	shorttitle = {Forecasting across time series databases using recurrent neural networks on groups of similar series},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417419306128},
	doi = {10.1016/j.eswa.2019.112896},
	abstract = {With the advent of Big Data, nowadays in many applications databases containing large quantities of similar time series are available. Forecasting time series in these domains with traditional univariate forecasting procedures leaves great potentials for producing accurate forecasts untapped. Recurrent neural networks (RNNs), and in particular Long Short Term Memory (LSTM) networks, have proven recently that they are able to outperform state-of-the-art univariate time series forecasting methods in this context, when trained across all available time series. However, if the time series database is heterogeneous, accuracy may degenerate, so that on the way towards fully automatic forecasting methods in this space, a notion of similarity between the time series needs to be built into the methods. To this end, we present a prediction model that can be used with different types of RNN models on subgroups of similar time series, which are identified by time series clustering techniques. We assess our proposed methodology using LSTM networks, a widely popular RNN variant, together with various clustering algorithms, such as kMeans, DBScan, Partition Around Medoids (PAM), and Snob. Our method achieves competitive results on benchmarking datasets under competition evaluation procedures. In particular, in terms of mean sMAPE accuracy it consistently outperforms the baseline LSTM model, and outperforms all other methods on the CIF2016 forecasting competition dataset.},
	urldate = {2024-07-13},
	journal = {Expert Systems with Applications},
	author = {Bandara, Kasun and Bergmeir, Christoph and Smyl, Slawek},
	month = {feb},
	year = {2020},
	keywords = {Big data forecasting, RNN, LSTM, Time series clustering, Neural networks},
	pages = {112896},
}

@article{hewamalage_recurrent_2021,
	title = {Recurrent {Neural} {Networks} for {Time} {Series} {Forecasting}: {Current} status and future directions},
	volume = {37},
	issn = {0169-2070},
	shorttitle = {Recurrent {Neural} {Networks} for {Time} {Series} {Forecasting}},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207020300996},
	doi = {10.1016/j.ijforecast.2020.06.008},
	abstract = {Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.},
	number = {1},
	urldate = {2024-07-13},
	journal = {International Journal of Forecasting},
	author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
	month = {jan},
	year = {2021},
	keywords = {Big data, Forecasting, Best practices, Framework},
	pages = {388--427},
}


@misc{gerboles_estimation_2010,
	title = {Estimation of the {Measurement} {Uncertainty} of {Ambient} {Air} {Pollution} {Datasets} {Using} {Geostatistical} {Analysis}},
	url = {https://publications.jrc.ec.europa.eu/repository/handle/JRC59441},
	abstract = {We developed a methodology able to automatically estimate of measurement uncertainty in the air pollution data sets of AIRBase. The figures produced with this method were consistent with expectations from laboratory and field estimation of uncertainty and with the Data Quality Objectives of the European Directives. The proposed method based on geostatistical analysis is not able to estimate directly the measurement uncertainty. It estimates the nugget effect together with a micro-scale variability that must be minimized by accurate selection of the type of station. Based on the results obtained so far, it is likely that measurement uncertainty is best estimated using all background stations of whatever area type. So far the methodology has been used to estimate uncertainty in 4 different countries independently. This work should be continued for the whole Europe or for background station without national borders. The method has been shown to be also useful to compare the spatial continuity of air pollution in different countries that seems to be influenced by the topography of each country.
Moreover, it may be used to quantify the trend of measurement uncertainty over long periods like decade with the possibility to evidence improvement in the data quality of AIRBase datasets.
Thanks to the implemented outlier detection module that would also be of interest as the warning system when Member States report they measurement to the European Environment Agency, we have proposed an easy solution to investigate wrong classified stations in AIRBase.},
	language = {en},
	urldate = {2024-07-14},
	journal = {JRC Publications Repository},
	author = {Gerboles, Michel and Reuter, Hannes I.},
	month = {oct},
	year = {2010},
	doi = {10.2788/44902},
}


@article{marecal_regional_2015,
	title = {A regional air quality forecasting system over {Europe}: the {MACC}-{II} daily ensemble production},
	volume = {8},
	issn = {1991-959X},
	shorttitle = {A regional air quality forecasting system over {Europe}},
	url = {https://gmd.copernicus.org/articles/8/2777/2015/},
	doi = {10.5194/gmd-8-2777-2015},
	abstract = {This paper describes the pre-operational analysis and forecasting system developed during MACC (Monitoring Atmospheric Composition and Climate) and continued in the MACC-II (Monitoring Atmospheric Composition and Climate: Interim Implementation) European projects to provide air quality services for the European continent. This system is based on seven state-of-the art models developed and run in Europe (CHIMERE, EMEP, EURAD-IM, LOTOS-EUROS, MATCH, MOCAGE and SILAM). These models are used to calculate multi-model ensemble products. The paper gives an overall picture of its status at the end of MACC-II (summer 2014) and analyses the performance of the multi-model ensemble. The MACC-II system provides daily 96 h forecasts with hourly outputs of 10 chemical species/aerosols (O3, NO2, SO2, CO, PM10, PM2.5, NO, NH3, total NMVOCs (non-methane volatile organic compounds) and PAN+PAN precursors) over eight vertical levels from the surface to 5 km height. The hourly analysis at the surface is done a posteriori for the past day using a selection of representative air quality data from European monitoring stations. 

 The performance of the system is assessed daily, weekly and every 3 months (seasonally) through statistical indicators calculated using the available representative air quality data from European monitoring stations. Results for a case study show the ability of the ensemble median to forecast regional ozone pollution events. The seasonal performances of the individual models and of the multi-model ensemble have been monitored since September 2009 for ozone, NO2 and PM10. The statistical indicators for ozone in summer 2014 show that the ensemble median gives on average the best performances compared to the seven models. There is very little degradation of the scores with the forecast day but there is a marked diurnal cycle, similarly to the individual models, that can be related partly to the prescribed diurnal variations of anthropogenic emissions in the models. During summer 2014, the diurnal ozone maximum is underestimated by the ensemble median by about 4 μg m−3 on average. Locally, during the studied ozone episodes, the maxima from the ensemble median are often lower than observations by 30–50 μg m−3. Overall, ozone scores are generally good with average values for the normalised indicators of 0.14 for the modified normalised mean bias and of 0.30 for the fractional gross error. Tests have also shown that the ensemble median is robust to reduction of ensemble size by one, that is, if predictions are unavailable from one model. Scores are also discussed for PM10 for winter 2013–1014. There is an underestimation of most models leading the ensemble median to a mean bias of −4.5 μg m−3. The ensemble median fractional gross error is larger for PM10 ({\textasciitilde} 0.52) than for ozone and the correlation is lower ({\textasciitilde} 0.35 for PM10 and {\textasciitilde} 0.54 for ozone). This is related to a larger spread of the seven model scores for PM10 than for ozone linked to different levels of complexity of aerosol representation in the individual models. In parallel, a scientific analysis of the results of the seven models and of the ensemble is also done over the Mediterranean area because of the specificity of its meteorology and emissions. 

 The system is robust in terms of the production availability. Major efforts have been done in MACC-II towards the operationalisation of all its components. Foreseen developments and research for improving its performances are discussed in the conclusion.},
	language = {English},
	number = {9},
	urldate = {2024-07-14},
	journal = {Geoscientific Model Development},
	author = {Marécal, V. and Peuch, V.-H. and Andersson, C. and Andersson, S. and Arteta, J. and Beekmann, M. and Benedictow, A. and Bergström, R. and Bessagnet, B. and Cansado, A. and Chéroux, F. and Colette, A. and Coman, A. and Curier, R. L. and Denier van der Gon, H. a. C. and Drouin, A. and Elbern, H. and Emili, E. and Engelen, R. J. and Eskes, H. J. and Foret, G. and Friese, E. and Gauss, M. and Giannaros, C. and Guth, J. and Joly, M. and Jaumouillé, E. and Josse, B. and Kadygrov, N. and Kaiser, J. W. and Krajsek, K. and Kuenen, J. and Kumar, U. and Liora, N. and Lopez, E. and Malherbe, L. and Martinez, I. and Melas, D. and Meleux, F. and Menut, L. and Moinat, P. and Morales, T. and Parmentier, J. and Piacentini, A. and Plu, M. and Poupkou, A. and Queguiner, S. and Robertson, L. and Rouïl, L. and Schaap, M. and Segers, A. and Sofiev, M. and Tarasson, L. and Thomas, M. and Timmermans, R. and Valdebenito, Á and van Velthoven, P. and van Versendaal, R. and Vira, J. and Ung, A.},
	month = {sep},
	year = {2015},
	pages = {2777--2813},
}


@misc{barcelonamesaure,
	title = {Pollution: daily and episodes {\textbar} {Air} {Quality} {\textbar} {Ajuntament} de {Barcelona}},
	shorttitle = {Pollution},
author="authorities",
	url = {https://ajuntament.barcelona.cat/qualitataire/en/pollution/pollution-daily-and-episodes},
	abstract = {Air contamination is present daily although punctual episodes are also registered. We explain you how to face these episodes of high contamination.},
	language = {en},
	urldate = {2024-08-17},
}

@misc{newdelhimeasure,
author="authorities",
	title = {Environment {Pollution} ({Prevention} \& {Control}) {Authority} for the {National} {Capital} {Region}},
	url = {https://www.epca.org.in/},
	urldate = {2024-08-17},
}


@misc{hettige_airphynet:_2024,
	title = {{AirPhyNet}: {Harnessing} {Physics}-{Guided} {Neural} {Networks} for {Air} {Quality} {Prediction}},
	shorttitle = {{AirPhyNet}},
	url = {http://arxiv.org/abs/2402.03784},
	doi = {10.48550/arXiv.2402.03784},
	abstract = {Air quality prediction and modelling plays a pivotal role in public health and environment management, for individuals and authorities to make informed decisions. Although traditional data-driven models have shown promise in this domain, their long-term prediction accuracy can be limited, especially in scenarios with sparse or incomplete data and they often rely on black-box deep learning structures that lack solid physical foundation leading to reduced transparency and interpretability in predictions. To address these limitations, this paper presents a novel approach named Physics guided Neural Network for Air Quality Prediction (AirPhyNet). Specifically, we leverage two well-established physics principles of air particle movement (diffusion and advection) by representing them as differential equation networks. Then, we utilize a graph structure to integrate physics knowledge into a neural network architecture and exploit latent representations to capture spatio-temporal relationships within the air quality data. Experiments on two real-world benchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art models for different testing scenarios including different lead time (24h, 48h, 72h), sparse data and sudden change prediction, achieving reduction in prediction errors up to 10\%. Moreover, a case study further validates that our model captures underlying physical processes of particle movement and generates accurate predictions with real physical meaning.},
	urldate = {2024-08-18},
	publisher = {arXiv},
	author = {Hettige, Kethmi Hirushini and Ji, Jiahao and Xiang, Shili and Long, Cheng and Cong, Gao and Wang, Jingyuan},
	month = {feb},
	year = {2024},
	note = {arXiv:2402.03784 [physics]
version: 2},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Physics - Applied Physics},
}


@article{chen_evaluating_2022,
	title = {Evaluating quantile forecasts in the {M5} uncertainty competition},
	volume = {38},
	url = {https://ideas.repec.org//a/eee/intfor/v38y2022i4p1531-1545.html},
	abstract = {Probabilistic forecasts are necessary for robust decisions in the face of uncertainty. The M5 Uncertainty competition required participating teams to forecast nine quantiles for unit sales of various products at various aggregation levels and for different time horizons. This paper evaluates the forecasting performance of the quantile forecasts at different aggregation levels and at different quantile levels. We contrast this with some theoretical predictions, and discuss potential implications and promising future research directions for the practice of probabilistic forecasting.},
	language = {en},
	number = {4},
	urldate = {2024-09-15},
	journal = {International Journal of Forecasting},
	author = {Chen, Zhi and Gaba, Anil and Tsetlin, Ilia and Winkler, Robert L.},
	year = {2022},
	keywords = {Quantile forecasts, Probabilistic forecasts, M competitions, Uncertainty, Retail sales forecasting},
	pages = {1531--1545},
}

@article{fernandez-jimenez_short-term_2023,
	series = {2022 {The} 3rd {International} {Conference} on {Power}, {Energy} and {Electrical} {Engineering}},
	title = {Short-term probabilistic forecasting models using {Beta} distributions for photovoltaic plants},
	volume = {9},
	issn = {2352-4847},
	url = {https://www.sciencedirect.com/science/article/pii/S2352484723000677},
	doi = {10.1016/j.egyr.2023.01.059},
	abstract = {This article presents original probabilistic forecasting models for day-ahead hourly energy generation forecasts for a photovoltaic (PV) plant, based on a semi-parametric approach using three deterministic forecasts. Input information of these new models consists of data of hourly weather forecasts obtained from a Numerical Weather Prediction model and variables related to the sun position for future instants. The proposed models were satisfactorily applied to the case study of a real-life PV plant in Portugal. Probabilistic benchmark models were also applied to the same case study and their forecasting results compared with the ones of the proposed models. The computer results obtained with these proposed models achieve better point and probabilistic forecasting evaluation indexes values than the ones obtained with the benchmark models.},
	urldate = {2024-09-15},
	journal = {Energy Reports},
	author = {Fernandez-Jimenez, L. Alfredo and Monteiro, Claudio and Ramirez-Rosado, Ignacio J.},
	month = {may},
	year = {2023},
	keywords = {Short-term forecasting, PV power generation, Probabilistic forecasting, Photovoltaic},
	pages = {495--502},
}


@article{wardana_estimation_2022,
	title = {Estimation of missing air pollutant data using a spatiotemporal convolutional autoencoder},
	volume = {34},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-022-07224-2},
	doi = {10.1007/s00521-022-07224-2},
	abstract = {A key challenge in building machine learning models for time series prediction is the incompleteness of the datasets. Missing data can arise for a variety of reasons, including sensor failure and network outages, resulting in datasets that can be missing significant periods of measurements. Models built using these datasets can therefore be biased. Although various methods have been proposed to handle missing data in many application areas, more air quality missing data prediction requires additional investigation. This study proposes an autoencoder model with spatiotemporal considerations to estimate missing values in air quality data. The model consists of one-dimensional convolution layers, making it flexible to cover spatial and temporal behaviours of air contaminants. This model exploits data from nearby stations to enhance predictions at the target station with missing data. This method does not require additional external features, such as weather and climate data. The results show that the proposed method effectively imputes missing data for discontinuous and long-interval interrupted datasets. Compared to univariate imputation techniques (most frequent, median and mean imputations), our model achieves up to 65\% RMSE improvement and 20–40\% against multivariate imputation techniques (decision tree, extra-trees, k-nearest neighbours and Bayesian ridge regressors). Imputation performance degrades when neighbouring stations are negatively correlated or weakly correlated.},
	language = {en},
	number = {18},
	urldate = {2024-10-13},
	journal = {Neural Computing and Applications},
	author = {Wardana, I. Nyoman Kusuma and Gardner, Julian W. and Fahmy, Suhaib A.},
	month = {sep},
	year = {2022},
	keywords = {
                Artificial Intelligence
            , Missing data, Air pollutant, Spatiotemporal, Autoencoder, Convolutional layer},
	pages = {16129--16154},
}

@misc{madrid_protocolo_no,
        author = {Ayuntamiento de Madrid},
	title = {Protocolo de actuación para episodios de contaminación por dióxido de nitrógeno - {Ayuntamiento} de {Madrid}},
	url = {https://www.madrid.es/portales/munimadrid/es/Inicio/Medidas-especiales-de-movilidad/Protocolo-de-contaminacion},
	abstract = {Contempla tres niveles (preaviso, aviso y alerta), en función de las concentraciones de dióxido de nitrógeno alcanzadas, y cinco escenarios de actuación con sus correspondientes medidas.},
	language = {es},
	urldate = {2024-10-26},
}

@article{gneiting_probabilistic_2007,
	title = {Probabilistic {Forecasts}, {Calibration} and {Sharpness}},
	volume = {69},
	issn = {1369-7412},
	url = {https://doi.org/10.1111/j.1467-9868.2007.00587.x},
	doi = {10.1111/j.1467-9868.2007.00587.x},
	abstract = {Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the US Pacific Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection.},
	number = {2},
	urldate = {2024-12-06},
	journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
	author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
	month = {apr},
	year = {2007},
	pages = {243--268},
}



@article{castro_multilayer_2017,
	title = {Multilayer perceptron architecture optimization using parallel computing techniques},
	volume = {12},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0189369},
	abstract = {The objective of this research was to develop a methodology for optimizing multilayer-perceptron-type neural networks by evaluating the effects of three neural architecture parameters, namely, number of hidden layers (HL), neurons per hidden layer (NHL), and activation function type (AF), on the sum of squares error (SSE). The data for the study were obtained from quality parameters (physicochemical and microbiological) of milk samples. Architectures or combinations were organized in groups (G1, G2, and G3) generated upon interspersing one, two, and three layers. Within each group, the networks had three neurons in the input layer, six neurons in the output layer, three to twenty-seven NHL, and three AF (tan-sig, log-sig, and linear) types. The number of architectures was determined using three factorial-type experimental designs, which reached 63, 2 187, and 50 049 combinations for G1, G2 and G3, respectively. Using MATLAB 2015a, a logical sequence was designed and implemented for constructing, training, and evaluating multilayer-perceptron-type neural networks using parallel computing techniques. The results show that HL and NHL have a statistically relevant effect on SSE, and from two hidden layers, AF also has a significant effect; thus, both AF and NHL can be evaluated to determine the optimal combination per group. Moreover, in the three study groups, it is observed that there is an inverse relationship between the number of processors and the total optimization time.},
	language = {eng},
	number = {12},
	journal = {PloS One},
	author = {Castro, Wilson and Oblitas, Jimy and Santa-Cruz, Roberto and Avila-George, Himer},
	year = {2017},
	pmid = {29236744},
	pmcid = {PMC5728525},
	keywords = {Algorithms, Animals, Cattle, Computers, Milk, Models, Neurological, Neural Networks, Computer},
	pages = {e0189369},
}

@article{ramchoun_multilayer_2016,
	title = {Multilayer {Perceptron}: {Architecture} {Optimization} and {Training}},
	volume = {4},
	issn = {1989-1660},
	shorttitle = {Multilayer {Perceptron}},
	url = {https://www.ijimai.org/journal/bibcite/reference/2523},
	language = {en},
	number = {Special Issue on Artificial Intelligence Underpinning},
	urldate = {2024-12-10},
	journal = {International Journal of Interactive Multimedia and Artificial Intelligence},
	author = {Ramchoun, Hassan and Ghanou, Youssef and Ettaouil, Mohamed and Idrissi, Mohammed Amine Janati},
	year = {2016},
	pages = {26--30},
}

@misc{doug_answer_2012,
	title = {Answer to "multi-layer perceptron ({MLP}) architecture: criteria for choosing number of hidden layers and size of the hidden layer?"},
	shorttitle = {Answer to "multi-layer perceptron ({MLP}) architecture},
	url = {https://stackoverflow.com/a/10568938},
	urldate = {2024-12-10},
	journal = {Stack Overflow},
	author = {{doug}},
	month = {may},
	year = {2012},
}


@article{makridakis_m5_2022_acc,
	series = {Special {Issue}: {M5} competition},
	title = {M5 accuracy competition: {Results}, findings, and conclusions},
	volume = {38},
	issn = {0169-2070},
	shorttitle = {M5 accuracy competition},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001874},
	doi = {10.1016/j.ijforecast.2021.11.013},
	abstract = {In this study, we present the results of the M5 “Accuracy” competition, which was the first of two parallel challenges in the latest M competition with the aim of advancing the theory and practice of forecasting. The main objective in the M5 “Accuracy” competition was to accurately predict 42,840 time series representing the hierarchical unit sales for the largest retail company in the world by revenue, Walmart. The competition required the submission of 30,490 point forecasts for the lowest cross-sectional aggregation level of the data, which could then be summed up accordingly to estimate forecasts for the remaining upward levels. We provide details of the implementation of the M5 “Accuracy” challenge, as well as the results and best performing methods, and summarize the major findings and conclusions. Finally, we discuss the implications of these findings and suggest directions for future research.},
	number = {4},
	urldate = {2024-12-31},
	journal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
	month = {oct},
	year = {2022},
	keywords = {Forecasting competitions, M competitions, Accuracy, Time series, Machine learning, Retail sales forecasting},
	pages = {1346--1364},
}

@article{makridakis_m5_2022_unc,
	series = {Special {Issue}: {M5} competition},
	title = {The {M5} uncertainty competition: {Results}, findings and conclusions},
	volume = {38},
	issn = {0169-2070},
	shorttitle = {The {M5} uncertainty competition},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001722},
	doi = {10.1016/j.ijforecast.2021.10.009},
	abstract = {This paper describes the M5 “Uncertainty” competition, the second of two parallel challenges of the latest M competition, aiming to advance the theory and practice of forecasting. The particular objective of the M5 “Uncertainty” competition was to accurately forecast the uncertainty distributions of the realized values of 42,840 time series that represent the hierarchical unit sales of the largest retail company in the world by revenue, Walmart. To do so, the competition required the prediction of nine different quantiles (0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, and 0.995), that can sufficiently describe the complete distributions of future sales. The paper provides details on the implementation and execution of the M5 “Uncertainty” competition, presents its results and the top-performing methods, and summarizes its major findings and conclusions. Finally, it discusses the implications of its findings and suggests directions for future research.},
	number = {4},
	urldate = {2024-12-31},
	journal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios and Chen, Zhi and Gaba, Anil and Tsetlin, Ilia and Winkler, Robert L.},
	month = {oct},
	year = {2022},
	keywords = {Forecasting competitions, M competitions, Uncertainty, Probabilistic forecasts, Time series, Machine learning, Retail sales forecasting},
	pages = {1365--1385},
}


@article{vega_garcia_shapley_2020,
	title = {Shapley additive explanations for {NO2} forecasting},
	volume = {56},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954119303498},
	doi = {10.1016/j.ecoinf.2019.101039},
	abstract = {In this paper, we address the problem of the interpretability of a machine learning model designed to predict air quality time series. When constructing a forecasting model, in addition to obtaining good accuracy, it is utterly important to understand why each prediction is made. Usually, interpreting the output of machine learning models is considered to be very difficult due to their complex “black box” architecture. However, we show how Shapley additive explanations can be used to interpret the outputs of a deep neural network designed to predict Nitrogen dioxide concentrations in Madrid. This method computes an estimation of the contribution of each feature for a particular prediction. Furthermore, we compare three explanatory methods to determine which one is more suitable for the air quality data and for the chosen machine learning model. A deeper insight into how the model behaves when predicting the pollution time series is obtained.},
	urldate = {2025-07-12},
	journal = {Ecological Informatics},
	author = {Vega García, María and Aznarte, José L.},
	month = {mar},
	year = {2020},
	keywords = {Air quality, Time series, Shapley additive explanations, Neural networks, Interpretability},
	pages = {101039},
}

@article{Silva2024,
  author    = {Silva, Sam J. and Keller, Christoph A.},
  title     = {Limitations of XAI Methods for Process-Level Understanding in the Atmospheric Sciences},
  journal   = {Artificial Intelligence for the Earth Systems},
  volume    = {3},
  number    = {1},
  year      = {2024},
  month     = {jan},
  doi       = {10.1175/AIES-D-23-0045.1},
  url       = {https://doi.org/10.1175/AIES-D-23-0045.1}
}

@article{rudin_stop_2019,
	title = {Stop {Explaining} {Black} {Box} {Machine} {Learning} {Models} for {High} {Stakes} {Decisions} and {Use} {Interpretable} {Models} {Instead}},
	volume = {1},
	issn = {2522-5839},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9122117/},
	doi = {10.1038/s42256-019-0048-x},
	abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward – it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
	number = {5},
	urldate = {2025-07-12},
	journal = {Nature machine intelligence},
	author = {Rudin, Cynthia},
	month = {may},
	year = {2019},
	pmid = {35603010},
	pmcid = {PMC9122117},
	pages = {206--215},
}

@book{hyndman2021,
  title={Forecasting: principles and practice},
  author={Hyndman, Rob J and Athanasopoulos, George},
  year={2021},
  edition={3rd},
  publisher={OTexts},
  url={https://otexts.com/fpp3/}
}

@book{bishop2006,
  title     = {Pattern Recognition and Machine Learning},
  author    = {Bishop, Christopher M.},
  year      = {2006},
  publisher = {Springer}
}
@book{gujarati2009,
  title     = {Basic Econometrics},
  author    = {Gujarati, Damodar N. and Porter, Dawn C.},
  year      = {2009},
  publisher = {McGraw-Hill Irwin},
  edition   = {5th}
}


@article{bergmeir_note_2018,
	title = {A note on the validity of cross-validation for evaluating autoregressive time series prediction},
	volume = {120},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947317302384},
	doi = {10.1016/j.csda.2017.11.003},
	abstract = {One of the most widely used standard procedures for model evaluation in classification and regression is K-fold cross-validation (CV). However, when it comes to time series forecasting, because of the inherent serial correlation and potential non-stationarity of the data, its application is not straightforward and often replaced by practitioners in favour of an out-of-sample (OOS) evaluation. It is shown that for purely autoregressive models, the use of standard K-fold CV is possible provided the models considered have uncorrelated errors. Such a setup occurs, for example, when the models nest a more appropriate model. This is very common when Machine Learning methods are used for prediction, and where CV can control for overfitting the data. Theoretical insights supporting these arguments are presented, along with a simulation study and a real-world example. It is shown empirically that K-fold CV performs favourably compared to both OOS evaluation and other time-series-specific techniques such as non-dependent cross-validation.},
	urldate = {2025-07-12},
	journal = {Computational Statistics \& Data Analysis},
	author = {Bergmeir, Christoph and Hyndman, Rob J. and Koo, Bonsoo},
	month = {apr},
	year = {2018},
	keywords = {Cross-validation, Time series, Autoregression},
	pages = {70--83},
}


@ARTICLE{humanout,
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and de Freitas, Nando},
  journal={Proceedings of the IEEE}, 
  title={Taking the Human Out of the Loop: A Review of Bayesian Optimization}, 
  year={2016},
  volume={104},
  number={1},
  pages={148-175},
  keywords={Big data;Bayes methods;Linear programming;Decision making;Design of experiments;Optimization;Genomes;Statistical analysis;decision making;design of experiments;optimization;response surface methodology;statistical learning;genomic medicine;Decision making;design of experiments;optimization;response surface methodology;statistical learning},
  doi={10.1109/JPROC.2015.2494218}}

@article{Bergstra2012,
  author    = {Bergstra, James and Bengio, Yoshua},
  title     = {Random search for hyper-parameter optimization},
  journal   = {The Journal of Machine Learning Research},
  volume    = {13},
  number    = {1},
  year      = {2012},
  month     = {feb},
  pages     = {281--305},
  url       = {http://dl.acm.org/citation.cfm?id=2188385.2188395}
}

@incollection{Platt1999,
  title     = {Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
  author    = {Platt, John},
  booktitle = {Advances in large margin classifiers},
  pages     = {61--74},
  year      = {1999},
  publisher = {MIT press}
}


@InProceedings{kuleshov18a,
  title = 	 {Accurate Uncertainties for Deep Learning Using Calibrated Regression},
  author =       {Kuleshov, Volodymyr and Fenner, Nathan and Ermon, Stefano},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2796--2804},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/kuleshov18a/kuleshov18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/kuleshov18a.html},
  abstract = 	 {Methods for reasoning under uncertainty are a key building block of accurate and reliable machine learning systems. Bayesian methods provide a general framework to quantify uncertainty. However, because of model misspecification and the use of approximate inference, Bayesian uncertainty estimates are often inaccurate {—} for example, a 90\% credible interval may not contain the true outcome 90\% of the time. Here, we propose a simple procedure for calibrating any regression algorithm; when applied to Bayesian and probabilistic models, it is guaranteed to produce calibrated uncertainty estimates given enough data. Our procedure is inspired by Platt scaling and extends previous work on classification. We evaluate this approach on Bayesian linear regression, feedforward, and recurrent neural networks, and find that it consistently outputs well-calibrated credible intervals while improving performance on time series forecasting and model-based reinforcement learning tasks.}
}


@inproceedings{Zadrozny2001HB,
  author    = {Zadrozny, Bianca and Elkan, Charles},
  title     = {Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers},
  booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning (ICML '01)},
  year      = {2001},
  pages     = {609--616},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA}
}


@inproceedings{niculescu-mizil_predicting_2005,
	address = {Bonn, Germany},
	title = {Predicting good probabilities with supervised learning},
	copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
	isbn = {9781595931801},
	url = {http://portal.acm.org/citation.cfm?doid=1102351.1102430},
	doi = {10.1145/1102351.1102430},
	language = {en},
	urldate = {2025-07-12},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning  - {ICML} '05},
	publisher = {ACM Press},
	author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
	year = {2005},
	pages = {625--632},
}

@misc{wang_calibration_2024,
	title = {Calibration in {Deep} {Learning}: {A} {Survey} of the {State}-of-the-{Art}},
	shorttitle = {Calibration in {Deep} {Learning}},
	url = {http://arxiv.org/abs/2308.01222},
	doi = {10.48550/arXiv.2308.01222},
	abstract = {Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent advances in calibrating deep models. In this survey, we review the state-of-the-art calibration methods and their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classify into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also cover recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Wang, Cheng},
	month = {may},
	year = {2024},
	note = {arXiv:2308.01222},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@misc{guo_calibration_2017,
	title = {On {Calibration} of {Modern} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.04599},
	doi = {10.48550/arXiv.1706.04599},
	abstract = {Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
	month = {aug},
	year = {2017},
	note = {arXiv:1706.04599},
	keywords = {Computer Science - Machine Learning},
}

@article{patel_quantile_2022,
	title = {A quantile mapping approach‐based bias correction in {Coupled} {Model} {Intercomparison} {Project} {Phase} 5 models for decadal temperature predictions over {India}},
	volume = {42},
	issn = {0899-8418, 1097-0088},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/joc.7376},
	doi = {10.1002/joc.7376},
	abstract = {Abstract
            Decadal climate prediction has been recognized as the important information for policy makers for agriculture, health and energy sectors and the general public for any near‐term planning. The modelling community is determined to put forward a reliable near‐term climate forecasting system, to predict annual to decadal state and variability of climate. However, deriving reliable information from the decadal prediction/hindcast is still a challenge. This study examines the decadal hindcast simulations of surface air temperature (SAT) over India in seven different ocean–atmosphere coupled models from the Coupled Model Intercomparison Project Phase 5 (CMIP5). Each decadal hindcast is available for the next 10‐years period from the initialized climate states of 1961–2006. The performance of models is assessed using different evaluation metrics, such as absolute mean difference, root mean square error, skill score and uncertainty in terms of the range of hindcasts. The multimodel ensemble mean displayed considerable skill in representing the spatial distribution of SAT over the Indian region except over the western Himalaya and Northeast India. Our results indicate that the decadal hindcasts skills improved noticeably when quantile mapping (QM) approach is used for the bias corrections. The major improvements are seen in terms of reducing absolute mean difference and uncertainty, regardless of lead time and region. The present study advocates that QM approach is useful not only for reducing bias but also for improving the decadal hindcast skill for SAT over India in the coupled models.},
	language = {en},
	number = {4},
	urldate = {2025-07-12},
	journal = {International Journal of Climatology},
	author = {Patel, Jayshri and Gnanaseelan, Chellappan and Chowdary, Jasti S. and Parekh, Anant},
	month = {mar},
	year = {2022},
	pages = {2455--2469},
}


@misc{kumar_verified_2020,
	title = {Verified {Uncertainty} {Calibration}},
	url = {http://arxiv.org/abs/1909.10155},
	doi = {10.48550/arXiv.1909.10155},
	abstract = {},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Kumar, Ananya and Liang, Percy and Ma, Tengyu},
	month = {jan},
	year = {2020},
	note = {arXiv:1909.10155},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}


@article{rakholia_multi-output_2023,
	title = {Multi-output machine learning model for regional air pollution forecasting in {Ho} {Chi} {Minh} {City}, {Vietnam}},
	volume = {173},
	issn = {1873-6750},
	doi = {10.1016/j.envint.2023.107848},
	abstract = {Air pollution concentrations in Ho Chi Minh City (HCMC) have been found to surpass the WHO standard, which has become a very serious problem affecting human health and the ecosystem. Various machine learning algorithms have recently been widely used in air quality forecasting studies to predict possible impacts. Training and constructing several machine learning models for different air pollutants, such as NO2, SO2, O3, and CO forecasts, is a time-consuming process that necessitates additional effort for deployment, maintenance, and monitoring. In this paper, an effort has been made to develop a multi-step multi-output multivariate model (a global model) for air quality forecasting, taking into account various parameters such as meteorological conditions, air quality data from urban traffic, residential, and industrial areas, urban space information, and time component for the prediction of NO2, SO2, O3, CO hourly (1 h to 24 h) concentrations. The global forecasting model can anticipate multiple air pollutant concentrations concurrently, based on past concentrations of covariate characteristics. The datasets on air pollution time series were gathered from six HealthyAir air quality monitoring sites in HCMC between February 2021 and August 2022. Darksky weather provided the hourly concentrations of meteorological conditions for the same period. This is the first model built using real-time air quality data for NO2, SO2, CO, and O3 forecasting in HCM city. To assess the effectiveness of the proposed model, it was evaluated using real data from HealthyAir stations and quantified using Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and correlation indices. The results show that the global air quality forecasting model beats earlier models built for air quality forecasting of each specific pollutant in HCMC.},
	language = {eng},
	journal = {Environment International},
	author = {Rakholia, Rajnish and Le, Quan and Quoc Ho, Bang and Vu, Khue and Simon Carbajo, Ricardo},
	month = {mar},
	year = {2023},
	pmid = {36842381},
	keywords = {Humans, Nitrogen Dioxide, Vietnam, Ecosystem, Air Pollution, Air Pollutants, Environmental Monitoring, Forecasting, Particulate Matter, Air quality forecasting, CO, HO Chi Minh City, Multi-output machine learning model, N-BEATS, NO(2), O(3), SO(2), Vietnam},
	pages = {107848},
}

@article{wesselkamp_advances_2025,
	title = {Advances in land surface forecasting: a comparison of {LSTM}, gradient boosting, and feed-forward neural networks as prognostic state emulators in a case study with {ecLand}},
	volume = {18},
	issn = {1991-959X},
	shorttitle = {Advances in land surface forecasting},
	url = {https://gmd.copernicus.org/articles/18/921/2025/},
	doi = {10.5194/gmd-18-921-2025},
	abstract = {The most useful weather prediction for the public is near the surface. The processes that are most relevant for near-surface weather prediction are also those that are most interactive and exhibit positive feedback or have key roles in energy partitioning. Land surface models (LSMs) consider these processes together with surface heterogeneity and, when coupled with an atmospheric model, provide boundary and initial conditions. They forecast water, carbon, and energy fluxes, which are an integral component of coupled atmospheric models. This numerical parametrization of atmospheric boundaries is computationally expensive, and statistical surrogate models are increasingly used to accelerate experimental research. We evaluated the efficiency of three surrogate models in simulating land surface processes for speeding up experimental research. Specifically, we compared the performance of a long short-term memory (LSTM) encoder–decoder network, extreme gradient boosting, and a feed-forward neural network within a physics-informed multi-objective framework. This framework emulates key prognostic states of the Integrated Forecasting System (IFS) land surface scheme of the European Centre for Medium-Range Weather Forecasts (ECMWF), ecLand, across continental and global scales. Our findings indicate that, while all models on average demonstrate high accuracy over the forecast period, the LSTM network excels in continental long-range predictions when carefully tuned, extreme gradient boosting (XGB) scores consistently high across tasks, and the multilayer perceptron (MLP) provides an excellent implementation time–accuracy trade-off. While their reliability is context-dependent, the runtime reductions achieved by the emulators in comparison to the full numerical models are significant, offering a faster alternative for conducting experiments on land surfaces.},
	language = {English},
	number = {4},
	urldate = {2025-07-12},
	journal = {Geoscientific Model Development},
	author = {Wesselkamp, Marieke and Chantry, Matthew and Pinnington, Ewan and Choulga, Margarita and Boussetta, Souhail and Kalweit, Maria and Bödecker, Joschka and Dormann, Carsten F. and Pappenberger, Florian and Balsamo, Gianpaolo},
	month = {feb},
	year = {2025},
	pages = {921--937},
}

@book{montgomery2012lrintroduction,
  author    = {Douglas C. Montgomery and Elizabeth A. Peck and G. Geoffrey Vining},
  title     = {Introduction to Linear Regression Analysis},
  edition   = {5th},
  publisher = {John Wiley \& Sons},
  address   = {Hoboken, NJ},
  year      = {2012},
  pages     = {672},
  month     = {apr}
}


@article{knnaltman_introduction_1992,
	title = {An {Introduction} to {Kernel} and {Nearest}-{Neighbor} {Nonparametric} {Regression}},
	volume = {46},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475879},
	doi = {10.1080/00031305.1992.10475879},
	language = {en},
	number = {3},
	urldate = {2025-07-12},
	journal = {The American Statistician},
	author = {Altman, N. S.},
	month = {aug},
	year = {1992},
	pages = {175--185},
}



@article{gradientfriedman_greedy_2001,
	title = {Greedy function approximation: {A} gradient boosting machine.},
	volume = {29},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Greedy function approximation},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full},
	doi = {10.1214/aos/1013203451},
	abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent “boosting” paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such “TreeBoost” models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
	number = {5},
	urldate = {2025-07-12},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome H.},
	month = {oct},
	year = {2001},
	keywords = {62-02, 62-07, 62-08, 62G08, 62H30, 68T10, boosting, decision trees, Function estimation, robust nonparametric regression},
	pages = {1189--1232},
}

@inproceedings{xgboostchen_xgboost:_2016,
	address = {San Francisco California USA},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {9781450342322},
	shorttitle = {{XGBoost}},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	language = {en},
	urldate = {2025-07-12},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = {aug},
	year = {2016},
	pages = {785--794},
}

@inproceedings{lightgbmke_lightgbm:_2017,
	title = {{LightGBM}: {A} {Highly} {Efficient} {Gradient} {Boosting} {Decision} {Tree}},
	volume = {30},
	shorttitle = {{LightGBM}},
	url = {https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html},
	abstract = {Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: {\textbackslash}emph\{Gradient-based One-Side Sampling\} (GOSS) and {\textbackslash}emph\{Exclusive Feature Bundling\} (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB {\textbackslash}emph\{LightGBM\}. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy.},
	urldate = {2025-07-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
	year = {2017},
}

@inproceedings{catboostprokhorenkova_catboost:_2018,
	title = {{CatBoost}: unbiased boosting with categorical features},
	volume = {31},
	shorttitle = {{CatBoost}},
	url = {https://papers.nips.cc/paper\_files/paper/2018/hash/14491b756b3a51daac41c24863285549-Abstract.html},
	abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
	urldate = {2025-07-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
	year = {2018},
}



@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2025-07-12},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = {oct},
	year = {2001},
	keywords = {
                Algorithms
            , 
                Categorization
            , 
                Forest Ecology
            , 
                Learning algorithms
            , 
                Machine Learning
            , 
                Statistical Learning
            , classification, regression, ensemble},
	pages = {5--32},
}

@article{mlprumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	copyright = {1986 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	language = {en},
	number = {6088},
	urldate = {2025-07-12},
	journal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	month = {oct},
	year = {1986},
	keywords = {Science, Humanities and Social Sciences, multidisciplinary, Science, multidisciplinary},
	pages = {533--536},
}

@misc{transvaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = {aug},
	year = {2023},
	note = {arXiv:1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{lstmhochreiter1997long,
  title        = {{Long Short-Term Memory}},
  author       = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal      = {Neural Computation},
  volume       = {9},
  number       = {8},
  pages        = {1735--1780},
  year         = {1997},
  month        = {nov},
  publisher    = {MIT Press},
  doi          = {10.1162/neco.1997.9.8.1735},
}



@misc{flowtimerasul_multivariate_2021,
	title = {Multivariate {Probabilistic} {Time} {Series} {Forecasting} via {Conditioned} {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2002.06103},
	doi = {10.48550/arXiv.2002.06103},
	abstract = {Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multivariate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multivariate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Rasul, Kashif and Sheikh, Abdul-Saboor and Schuster, Ingmar and Bergmann, Urs and Vollgraf, Roland},
	month = {jan},
	year = {2021},
	note = {arXiv:2002.06103},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{imagetan_flowvqtalker:_2024,
	title = {{FlowVQTalker}: {High}-{Quality} {Emotional} {Talking} {Face} {Generation} through {Normalizing} {Flow} and {Quantization}},
	shorttitle = {{FlowVQTalker}},
	url = {http://arxiv.org/abs/2403.06375},
	doi = {10.48550/arXiv.2403.06375},
	abstract = {Generating emotional talking faces is a practical yet challenging endeavor. To create a lifelike avatar, we draw upon two critical insights from a human perspective: 1) The connection between audio and the non-deterministic facial dynamics, encompassing expressions, blinks, poses, should exhibit synchronous and one-to-many mapping. 2) Vibrant expressions are often accompanied by emotion-aware high-definition (HD) textures and finely detailed teeth. However, both aspects are frequently overlooked by existing methods. To this end, this paper proposes using normalizing Flow and Vector-Quantization modeling to produce emotional talking faces that satisfy both insights concurrently (FlowVQTalker). Specifically, we develop a flow-based coefficient generator that encodes the dynamics of facial emotion into a multi-emotion-class latent space represented as a mixture distribution. The generation process commences with random sampling from the modeled distribution, guided by the accompanying audio, enabling both lip-synchronization and the uncertain nonverbal facial cues generation. Furthermore, our designed vector-quantization image generator treats the creation of expressive facial images as a code query task, utilizing a learned codebook to provide rich, high-quality textures that enhance the emotional perception of the results. Extensive experiments are conducted to showcase the effectiveness of our approach.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Tan, Shuai and Ji, Bin and Pan, Ye},
	month = {apr},
	year = {2024},
	note = {arXiv:2403.06375},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{flowaudiobilinski_creating_2023,
	title = {Creating {New} {Voices} using {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2312.14569},
	doi = {10.48550/arXiv.2312.14569},
	abstract = {Creating realistic and natural-sounding synthetic speech remains a big challenge for voice identities unseen during training. As there is growing interest in synthesizing voices of new speakers, here we investigate the ability of normalizing flows in text-to-speech (TTS) and voice conversion (VC) modes to extrapolate from speakers observed during training to create unseen speaker identities. Firstly, we create an approach for TTS and VC, and then we comprehensively evaluate our methods and baselines in terms of intelligibility, naturalness, speaker similarity, and ability to create new voices. We use both objective and subjective metrics to benchmark our techniques on 2 evaluation tasks: zero-shot and new voice speech synthesis. The goal of the former task is to measure the precision of the conversion to an unseen voice. The goal of the latter is to measure the ability to create new voices. Extensive evaluations demonstrate that the proposed approach systematically allows to obtain state-of-the-art performance in zero-shot speech synthesis and creates various new voices, unobserved in the training set. We consider this work to be the first attempt to synthesize new voices based on mel-spectrograms and normalizing flows, along with a comprehensive analysis and comparison of the TTS and VC modes.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Bilinski, Piotr and Merritt, Thomas and Ezzerg, Abdelhamid and Pokora, Kamil and Cygert, Sebastian and Yanagisawa, Kayoko and Barra-Chicote, Roberto and Korzekwa, Daniel},
	month = {dec},
	year = {2023},
	note = {arXiv:2312.14569},
	keywords = {Computer Science - Sound, Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@misc{diftimemeijer_rise_2024,
	title = {The {Rise} of {Diffusion} {Models} in {Time}-{Series} {Forecasting}},
	url = {http://arxiv.org/abs/2401.03006},
	doi = {10.48550/arXiv.2401.03006},
	abstract = {This survey delves into the application of diffusion models in time-series forecasting. Diffusion models are demonstrating state-of-the-art results in various fields of generative AI. The paper includes comprehensive background information on diffusion models, detailing their conditioning methods and reviewing their use in time-series forecasting. The analysis covers 11 specific time-series implementations, the intuition and theory behind them, the effectiveness on different datasets, and a comparison among each other. Key contributions of this work are the thorough exploration of diffusion models' applications in time-series forecasting and a chronologically ordered overview of these models. Additionally, the paper offers an insightful discussion on the current state-of-the-art in this domain and outlines potential future research directions. This serves as a valuable resource for researchers in AI and time-series analysis, offering a clear view of the latest advancements and future potential of diffusion models.},
	urldate = {2025-07-12},
	publisher = {arXiv},
	author = {Meijer, Caspar and Chen, Lydia Y.},
	month = {jan},
	year = {2024},
	note = {arXiv:2401.03006},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}



@article{garcia_advanced_2010,
	series = {Special {Issue} on {Intelligent} {Distributed} {Information} {Systems}},
	title = {Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: {Experimental} analysis of power},
	volume = {180},
	issn = {0020-0255},
	shorttitle = {Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025509005404},
	doi = {10.1016/j.ins.2009.12.010},
	abstract = {Experimental analysis of the performance of a proposed method is a crucial and necessary task in an investigation. In this paper, we focus on the use of nonparametric statistical inference for analyzing the results obtained in an experiment design in the field of computational intelligence. We present a case study which involves a set of techniques in classification tasks and we study a set of nonparametric procedures useful to analyze the behavior of a method with respect to a set of algorithms, such as the framework in which a new proposal is developed. Particularly, we discuss some basic and advanced nonparametric approaches which improve the results offered by the Friedman test in some circumstances. A set of post hoc procedures for multiple comparisons is presented together with the computation of adjusted p-values. We also perform an experimental analysis for comparing their power, with the objective of detecting the advantages and disadvantages of the statistical tests described. We found that some aspects such as the number of algorithms, number of data sets and differences in performance offered by the control method are very influential in the statistical tests studied. Our final goal is to offer a complete guideline for the use of nonparametric statistical procedures for performing multiple comparisons in experimental studies.},
	number = {10},
	urldate = {2025-07-20},
	journal = {Information Sciences},
	author = {García, Salvador and Fernández, Alberto and Luengo, Julián and Herrera, Francisco},
	month = may,
	year = {2010},
	keywords = {Statistical analysis, Computational intelligence, Data mining, Nonparametric statistics, Multiple comparisons procedures, Genetics-based machine learning, Fuzzy classification systems},
	pages = {2044--2064},
}
